{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6644fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9f947f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8111719",
   "metadata": {},
   "source": [
    "# Transition Risk Analysis\n",
    "\n",
    "## Objective\n",
    "This script analyzes and projects Scope 1 and Scope 2 emissions for companies from 2025 to 2050, calculates carbon costs under different scenarios, evaluates abatement costs, and assesses tradeoffs between paying carbon prices and investing in abatement. The goal is to estimate future emissions paths and financial implications of carbon pricing for companies across various sectors and regions, using data from S&P Global.\n",
    "\n",
    "## Key Functionalities\n",
    "1. **Data Loading and Cleaning**:\n",
    "   - Loads data from an Excel file containing emissions, reduction targets, abatement costs, and carbon prices.\n",
    "   - Cleans data by standardizing column names, handling missing values, and correcting year formats.\n",
    "\n",
    "2. **Emissions Projection**:\n",
    "   - Projects Scope 1 and Scope 2 emissions to 2050 using absolute or intensity-based reduction targets.\n",
    "   - Supports constant production or user-defined growth rates for intensity-based projections.\n",
    "\n",
    "3. **Carbon Pricing Calculations**:\n",
    "   - Computes carbon costs by multiplying projected emissions by scenario-specific carbon prices.\n",
    "   - Includes a fallback to global carbon prices if region-specific prices are unavailable.\n",
    "   - Aggregates abatement costs per company and calculates net savings from abatement vs. paying carbon costs.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Generates plots, including:\n",
    "     - Stacked area chart of emissions by sector.\n",
    "     - Heatmap of average carbon costs by scenario and year.\n",
    "     - Waterfall chart comparing pay-only vs. abatement costs for a company.\n",
    "     - Box plot of carbon cost distribution by country.\n",
    "     - Scatter plot of abatement investment vs. net savings.\n",
    "     - Carbon price projection curves for a sector and region.\n",
    "\n",
    "## Data Requirements\n",
    "- **Input File**: `S&P Global S1 Transition Risk Data.xlsx` with:\n",
    "  - Table 1: Emissions data (uid, gics_sector, country, year, scope1_tonnes, scope2_tonnes, unit_production, production_volume).\n",
    "  - Table 2: Reduction targets (uid, type_of_target, reduction_target, baseline, endline, etc.).\n",
    "  - Table 3: Abatement costs (uid, abatement_cost_usd_year).\n",
    "  - Table 4: Carbon prices (sector, region, year, scenario, carbon_price_usd_tco2e).\n",
    "- **Dependencies**: `pandas`, `numpy`, `matplotlib`, `seaborn`, `openpyxl`.\n",
    "\n",
    "## Usage\n",
    "- Run the script directly (`transition_risk_analysis.py`) or in a Jupyter notebook.\n",
    "- Ensure the Excel file is in the project directory.\n",
    "- Install dependencies: `pip install pandas numpy matplotlib seaborn openpyxl`.\n",
    "\n",
    "## Notes\n",
    "- Missing values in emissions are imputed using median values by sector and size category.\n",
    "- Carbon prices use region-specific values with a fallback to global prices.\n",
    "- The script assumes a 0% production growth rate; adjust `production_growth_rate` in `project_emissions` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfbcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671822bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions rows : 50\n",
      "Targets rows   : 50\n",
      "Abatement rows : 60\n",
      "Carbon price rows: 225\n",
      "Merged rows    : 50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "streamlined_transition_risk_etl.py\n",
    "----------------------------------\n",
    "End-to-end ETL for the S&P Global S1 Transition-Risk workbook.\n",
    "\n",
    "Outputs:\n",
    "    df_emissions      – cleaned + imputed emissions (Table 1)\n",
    "    df_targets_clean  – cleaned company targets (Table 2)\n",
    "    df_abatement      – cleaned abatement catalogue (Table 3)\n",
    "    df_carbon_prices  – cleaned carbon-price assumptions (Table 4)\n",
    "    df_merged         – targets ⟷ emissions join, for modelling\n",
    "\"\"\"\n",
    "\n",
    "# ── Imports ─────────────────────────────────────────────────────────────────────\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# ── Global config ──────────────────────────────────────────────────────────────\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "FILE_PATH = \"S&P Global S1 Transition Risk Data.xlsx\"\n",
    "\n",
    "YEAR_REPLACEMENTS = {\"2,025\": 2025, \"202five\": 2025}\n",
    "COUNTRY_REPLACEMENTS = {\"EUROPE\": \"EU\", \"Europa\": \"EU\"}\n",
    "\n",
    "# ── Helper functions ───────────────────────────────────────────────────────────\n",
    "def clean_country_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Fill missing and harmonise EU shorthand.\"\"\"\n",
    "    return s.fillna(\"Unknown\").replace(COUNTRY_REPLACEMENTS)\n",
    "\n",
    "\n",
    "def clean_year_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Standardise year strings → integers.\"\"\"\n",
    "    s = s.replace(YEAR_REPLACEMENTS).astype(str).str.replace(\",\", \"\").str.strip()\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "\n",
    "def to_numeric_series(s: pd.Series, *, non_neg: bool = True) -> pd.Series:\n",
    "    \"\"\"Coerce to numeric, optionally clipping negatives.\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.clip(lower=0) if non_neg else s\n",
    "\n",
    "\n",
    "def impute_missing_emissions(df: pd.DataFrame, *, sector: str = \"Materials\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fill NA scope-1 / scope-2 values for `sector` with size-bucket medians\n",
    "    (buckets based on production-volume terciles).\n",
    "    \"\"\"\n",
    "    full = df.copy()\n",
    "    sect = full[full[\"gics_sector\"] == sector]\n",
    "\n",
    "    if sect[[\"scope1_tonnes\", \"scope2_tonnes\"]].notna().all(axis=None):\n",
    "        return full  # nothing to do\n",
    "\n",
    "    lo, hi = sect[\"production_volume\"].quantile([0.33, 0.66])\n",
    "\n",
    "    def bucket(v):\n",
    "        if pd.isna(v):\n",
    "            return \"Medium\"\n",
    "        if v <= lo:\n",
    "            return \"Small\"\n",
    "        if v <= hi:\n",
    "            return \"Medium\"\n",
    "        return \"Large\"\n",
    "\n",
    "    sect = sect.assign(size_category=sect[\"production_volume\"].apply(bucket))\n",
    "    med = sect.groupby(\"size_category\")[[\"scope1_tonnes\", \"scope2_tonnes\"]].median()\n",
    "\n",
    "    for col in (\"scope1_tonnes\", \"scope2_tonnes\"):\n",
    "        na_idx = sect[sect[col].isna()].index\n",
    "        for i in na_idx:\n",
    "            full.loc[i, col] = med.loc[sect.at[i, \"size_category\"], col]\n",
    "\n",
    "    return full\n",
    "\n",
    "# ── Helper updates ─────────────────────────────────────────────────────────────\n",
    "YEAR_WORDS = {\n",
    "    \"twenty-twenty\": 2020,\n",
    "    \"twenty twenty\": 2020,\n",
    "    \"2,024\": 2024,\n",
    "    \"202four\": 2024,\n",
    "    \"forty\": 40,           # used in reduction parsing\n",
    "}\n",
    "\n",
    "def clean_year_word(val):\n",
    "    \"\"\"Handle words / commas → nullable int.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return pd.NA\n",
    "    txt = str(val).strip().lower().replace(\",\", \"\")\n",
    "    if txt in YEAR_WORDS:\n",
    "        return YEAR_WORDS[txt]\n",
    "    return pd.to_numeric(txt, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "def split_reduction(val):\n",
    "    \"\"\"\n",
    "    Parse `reduction_target` Free-text → (value, type, unit)\n",
    "       • 40 %  → 0.40, 'absolute', '%'\n",
    "       • 1.2 tCO2e/t           → intensity\n",
    "       • unknown / non-parse   → NaNs\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, \"unknown\", None])\n",
    "    t = str(val).strip().lower()\n",
    "\n",
    "    # exact patterns (e.g. \"40%\" or \"forty%\")\n",
    "    if t in {\"40%\", \"forty%\"}:\n",
    "        return pd.Series([0.40, \"absolute\", \"%\"])\n",
    "\n",
    "    # explicit intensity strings\n",
    "    m = re.match(r\"([0-9]*\\.?[0-9]+)\\s*tco2e/?(.+)?\", t)\n",
    "    if m:\n",
    "        num = float(m.group(1))\n",
    "        unit = f\"tCO2e/{m.group(2).strip()}\" if m.group(2) else \"tCO2e\"\n",
    "        return pd.Series([num, \"intensity\", unit])\n",
    "\n",
    "    # other % entries\n",
    "    if t.endswith(\"%\"):\n",
    "        try:\n",
    "            num = float(t.replace(\"%\", \"\")) / 100\n",
    "            return pd.Series([num, \"absolute\", \"%\"])\n",
    "        except ValueError:\n",
    "            return pd.Series([np.nan, \"absolute\", \"%\"])\n",
    "\n",
    "    # bare number\n",
    "    try:\n",
    "        num = float(t)\n",
    "        num = num / 100 if num > 1 else num\n",
    "        return pd.Series([num, \"absolute\", \"%\"])\n",
    "    except ValueError:\n",
    "        return pd.Series([np.nan, \"unknown\", None])\n",
    "\n",
    "\n",
    "# ── ETL ────────────────────────────────────────────────────────────────────────\n",
    "def run_etl(path: str = FILE_PATH):\n",
    "    # ---- Load all sheets in one go ----\n",
    "    sheets = pd.read_excel(path, sheet_name=None)\n",
    "    raw_emissions = sheets[\"Table 1\"]\n",
    "    raw_targets   = sheets[\"Table 2\"]\n",
    "    raw_abatement = sheets[\"Table 3\"]\n",
    "    raw_prices    = sheets[\"Table 4\"]\n",
    "\n",
    "    # ---- Table 1 – Emissions ----\n",
    "    df_em = raw_emissions.copy()\n",
    "    df_em.columns = [\n",
    "        \"uid\", \"gics_sector\", \"country\", \"year\",\n",
    "        \"scope1_tonnes\", \"scope2_tonnes\",\n",
    "        \"unit_production\", \"production_volume\",\n",
    "    ]\n",
    "    df_em = (\n",
    "        df_em.drop_duplicates(\"uid\")\n",
    "             .assign(\n",
    "                 country = clean_country_series(df_em[\"country\"]),\n",
    "                 year    = clean_year_series(df_em[\"year\"]),\n",
    "                 scope1_tonnes = to_numeric_series(df_em[\"scope1_tonnes\"]),\n",
    "                 scope2_tonnes = to_numeric_series(df_em[\"scope2_tonnes\"]),\n",
    "                 production_volume = pd.to_numeric(\n",
    "                     df_em[\"production_volume\"], errors=\"coerce\"\n",
    "                 ).fillna(0),\n",
    "             )\n",
    "    )\n",
    "    df_em = impute_missing_emissions(df_em, sector=\"Materials\")\n",
    "\n",
    "        # ---- Table 2 – Targets --------------------------------------------------------\n",
    "    df_t = raw_targets.copy()\n",
    "    df_t.columns = [\n",
    "        \"uid\", \"type_of_target\", \"reduction_target\",\n",
    "        \"baseline\", \"endline\", \"comment\",\n",
    "    ]\n",
    "\n",
    "    # 1. clean years\n",
    "    df_t[\"baseline_year\"] = df_t[\"baseline\"].apply(clean_year_word).astype(\"Int64\")\n",
    "    df_t[\"endline_year\"]  = df_t[\"endline\"].apply(clean_year_word).astype(\"Int64\")\n",
    "    df_t = df_t.drop(columns=[\"baseline\", \"endline\"])\n",
    "\n",
    "    # 2. parse reduction_target → value / type / unit\n",
    "    df_t[[\"reduction_value\", \"reduction_type\", \"reduction_unit\"]] = (\n",
    "        df_t[\"reduction_target\"].apply(split_reduction)\n",
    "    )\n",
    "\n",
    "    # 3. **NEW** hard filter: keep only rows that *have* a numeric value\n",
    "    df_t = df_t.dropna(subset=[\"reduction_value\"])\n",
    "\n",
    "    # 4. cast to float once (pd.NA → np.nan is now impossible, but keeps dtype uniform)\n",
    "    df_t[\"reduction_value\"] = df_t[\"reduction_value\"].astype(float)\n",
    "\n",
    "    # 5. tidy + order\n",
    "    df_targets_clean = (\n",
    "        df_t[\n",
    "            [\n",
    "                \"uid\", \"type_of_target\", \"reduction_target\",\n",
    "                \"reduction_value\", \"reduction_type\", \"reduction_unit\",\n",
    "                \"baseline_year\", \"endline_year\", \"comment\",\n",
    "            ]\n",
    "        ]\n",
    "        .sort_values([\"uid\", \"type_of_target\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    # ---- Table 3 – Abatement catalogue ----\n",
    "    df_ab = raw_abatement.copy()\n",
    "    df_ab.columns = [\n",
    "        \"sector\", \"region\", \"technology\",\n",
    "        \"initial_investment_usd_million\",\n",
    "        \"abatement_capacity_tco2e_year\",\n",
    "        \"abatement_cost_usd_tco2e_year\",\n",
    "    ]\n",
    "    df_ab[\"region\"] = df_ab[\"region\"].replace(COUNTRY_REPLACEMENTS)\n",
    "    df_ab[\"abatement_cost_usd_tco2e_year\"] = (\n",
    "        df_ab[\"abatement_cost_usd_tco2e_year\"]\n",
    "              .replace({\"eighty\": 80})\n",
    "              .astype(float)\n",
    "    )\n",
    "    df_ab[\"initial_investment_usd_million\"] = (\n",
    "        df_ab[\"initial_investment_usd_million\"]\n",
    "              .fillna(df_ab.groupby(\"sector\")[\"initial_investment_usd_million\"].transform(\"mean\"))\n",
    "    )\n",
    "\n",
    "    # ---- Table 4 – Carbon prices ----\n",
    "    df_cp = raw_prices.copy()\n",
    "    df_cp.columns = [\"sector\", \"region\", \"year\", \"scenario\", \"carbon_price_usd_tco2e\"]\n",
    "    df_cp[\"region\"] = df_cp[\"region\"].replace(COUNTRY_REPLACEMENTS)\n",
    "    df_cp[\"carbon_price_usd_tco2e\"] = (\n",
    "        pd.to_numeric(df_cp[\"carbon_price_usd_tco2e\"], errors=\"coerce\")\n",
    "          .fillna(df_cp.groupby(\"scenario\")[\"carbon_price_usd_tco2e\"].transform(\"median\"))\n",
    "    )\n",
    "\n",
    "    # ---- Join targets ↔ emissions ----\n",
    "    df_merged = (\n",
    "        df_targets_clean\n",
    "            .merge(df_em, on=\"uid\", how=\"left\", indicator=True)\n",
    "            .rename(columns={\"_merge\": \"merge_status\"})\n",
    "    )\n",
    "\n",
    "    return df_em, df_targets_clean, df_ab, df_cp, df_merged\n",
    "\n",
    "\n",
    "# ── Script entry-point ─────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable pandas future warnings once for reproducibility\n",
    "    pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "    (\n",
    "        df_emissions,\n",
    "        df_targets_clean,\n",
    "        df_abatement,\n",
    "        df_carbon_prices,\n",
    "        df_merged,\n",
    "    ) = run_etl()\n",
    "\n",
    "    # Quick sanity printout\n",
    "    print(f\"Emissions rows : {len(df_emissions):,}\")\n",
    "    print(f\"Targets rows   : {len(df_targets_clean):,}\")\n",
    "    print(f\"Abatement rows : {len(df_abatement):,}\")\n",
    "    print(f\"Carbon price rows: {len(df_carbon_prices):,}\")\n",
    "    print(f\"Merged rows    : {len(df_merged):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.query(\"uid == 'C026'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_clean.query(\"uid == 'C026'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70185001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions.query(\"uid == 'C026'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b161482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Set visualization style for consistent plotting\n",
    "# sns.set(style=\"whitegrid\")\n",
    "\n",
    "# # Constants\n",
    "# FILE_PATH = \"S&P Global S1 Transition Risk Data.xlsx\"\n",
    "# YEAR_REPLACEMENTS = {'2,025': 2025, '202five': 2025}\n",
    "\n",
    "# # Objective: Load emissions data from an Excel file and clean it by standardizing column names,\n",
    "# # removing duplicates, correcting country and year formats, and ensuring emissions are numeric and non-negative.\n",
    "# # This prepares the data for imputation and downstream analysis.\n",
    "\n",
    "# def load_and_clean_emissions(file_path):\n",
    "#     \"\"\"\n",
    "#     Load and clean emissions data from Excel.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path to the Excel file.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: Cleaned emissions data.\n",
    "#     \"\"\"\n",
    "#     # Load emissions data\n",
    "#     df_emissions = pd.read_excel(file_path, sheet_name=\"Table 1\")\n",
    "    \n",
    "#     # Standardize column names\n",
    "#     df_emissions.columns = ['uid', 'gics_sector', 'country', 'year', 'scope1_tonnes',\n",
    "#                             'scope2_tonnes', 'unit_production', 'production_volume']\n",
    "    \n",
    "#     # Remove duplicates, clean country and year columns\n",
    "#     df_emissions = df_emissions.drop_duplicates(subset='uid', keep='first')\n",
    "#     df_emissions['country'] = df_emissions['country'].fillna('Unknown').replace({'EUROPE': 'EU'})\n",
    "#     df_emissions['year'] = df_emissions['year'].replace(YEAR_REPLACEMENTS).astype(int)\n",
    "    \n",
    "#     # Convert emissions to numeric, handle invalid values, and ensure non-negative\n",
    "#     df_emissions[['scope1_tonnes', 'scope2_tonnes']] = df_emissions[['scope1_tonnes', 'scope2_tonnes']].apply(\n",
    "#         lambda x: pd.to_numeric(x, errors='coerce').clip(lower=0))\n",
    "    \n",
    "#     return df_emissions\n",
    "\n",
    "# # Objective: Impute missing Scope 1 and Scope 2 emissions values for a specified sector (default: Materials)\n",
    "# # using median emissions from companies of similar size, based on production volume quantiles.\n",
    "# # This ensures a complete dataset for accurate emissions projections.\n",
    "\n",
    "# def impute_missing_emissions(df_emissions, sector='Materials'):\n",
    "#     \"\"\"\n",
    "#     Impute missing emissions values for a specified sector using size-based median.\n",
    "\n",
    "#     Args:\n",
    "#         df_emissions (DataFrame): Emissions data with potential missing values.\n",
    "#         sector (str): Sector to impute (default: 'Materials').\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: Emissions data with imputed values.\n",
    "#     \"\"\"\n",
    "#     df = df_emissions.copy()\n",
    "#     sector_df = df[df['gics_sector'] == sector].copy()\n",
    "    \n",
    "#     # Skip imputation if no missing values\n",
    "#     if not sector_df['scope1_tonnes'].isna().any() and not sector_df['scope2_tonnes'].isna().any():\n",
    "#         return df\n",
    "    \n",
    "#     # Define size categories based on production volume\n",
    "#     small_threshold = sector_df['production_volume'].quantile(0.33)\n",
    "#     large_threshold = sector_df['production_volume'].quantile(0.66)\n",
    "    \n",
    "#     def categorize_size(volume):\n",
    "#         \"\"\"Categorize company size based on production volume.\"\"\"\n",
    "#         if pd.isna(volume):\n",
    "#             return 'Medium'\n",
    "#         if volume <= small_threshold:\n",
    "#             return 'Small'\n",
    "#         elif volume <= large_threshold:\n",
    "#             return 'Medium'\n",
    "#         return 'Large'\n",
    "    \n",
    "#     sector_df['size_category'] = sector_df['production_volume'].apply(categorize_size)\n",
    "    \n",
    "#     # Calculate median emissions by size category\n",
    "#     size_medians = sector_df.groupby('size_category')[['scope1_tonnes', 'scope2_tonnes']].median()\n",
    "    \n",
    "#     # Impute missing values\n",
    "#     for col in ['scope1_tonnes', 'scope2_tonnes']:\n",
    "#         missing_indices = sector_df[sector_df[col].isna()].index\n",
    "#         for idx in missing_indices:\n",
    "#             size_cat = sector_df.loc[idx, 'size_category']\n",
    "#             df.loc[idx, col] = size_medians.loc[size_cat, col]\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def validate_emissions(df_emissions, sector='Materials'):\n",
    "#     \"\"\"\n",
    "#     Validate emissions data by checking for missing values and summarizing results.\n",
    "\n",
    "#     Args:\n",
    "#         df_emissions (DataFrame): Emissions data to validate.\n",
    "#         sector (str): Sector to focus validation on (default: 'Materials').\n",
    "\n",
    "#     Returns:\n",
    "#         None: Prints validation results.\n",
    "#     \"\"\"\n",
    "#     # Check missing values\n",
    "#     missing_scope1 = df_emissions['scope1_tonnes'].isna().sum()\n",
    "#     missing_scope2 = df_emissions['scope2_tonnes'].isna().sum()\n",
    "#     total_rows = len(df_emissions)\n",
    "#     print(f\"Missing values in scope1_tonnes: {missing_scope1} ({missing_scope1 / total_rows * 100:.2f}%)\")\n",
    "#     print(f\"Missing values in scope2_tonnes: {missing_scope2} ({missing_scope2 / total_rows * 100:.2f}%)\")\n",
    "    \n",
    "#     # Missing values by sector\n",
    "#     missing_by_sector = df_emissions.groupby('gics_sector')[['scope1_tonnes', 'scope2_tonnes']].apply(\n",
    "#         lambda x: x.isna().sum())\n",
    "#     print(\"Missing values by sector:\\n\", missing_by_sector)\n",
    "    \n",
    "#     # Validate imputed values for the specified sector\n",
    "#     sector_df = df_emissions[df_emissions['gics_sector'] == sector].copy()\n",
    "#     if not sector_df.empty:\n",
    "#         small_threshold = sector_df['production_volume'].quantile(0.33)\n",
    "#         large_threshold = sector_df['production_volume'].quantile(0.66)\n",
    "#         sector_df['size_category'] = sector_df['production_volume'].apply(\n",
    "#             lambda x: 'Small' if x <= small_threshold else 'Medium' if x <= large_threshold else 'Large')\n",
    "        \n",
    "#         print(f\"Updated {sector} sector data:\\n\", sector_df)\n",
    "#         for size_cat in sector_df['size_category'].unique():\n",
    "#             print(f\"scope1_tonnes stats for {size_cat} companies in {sector}:\\n\",\n",
    "#                   sector_df[sector_df['size_category'] == size_cat]['scope1_tonnes'].describe())\n",
    "\n",
    "# # Objective: Orchestrate the loading, cleaning, imputation, and validation of emissions data.\n",
    "# # This serves as the entry point for the script, ensuring all steps are executed in order.\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main function to load, clean, impute, and validate emissions data.\"\"\"\n",
    "#     # Suppress pandas FutureWarning for downcasting\n",
    "#     pd.set_option('future.no_silent_downcasting', True)\n",
    "    \n",
    "#     # Load and clean emissions data\n",
    "#     df_emissions = load_and_clean_emissions(FILE_PATH)\n",
    "    \n",
    "#     # Impute missing values for Materials sector\n",
    "#     df_emissions = impute_missing_emissions(df_emissions, sector='Materials')\n",
    "    \n",
    "#     # Validate and print results\n",
    "#     validate_emissions(df_emissions, sector='Materials')\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e59330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Set visualization style\n",
    "# sns.set(style=\"whitegrid\")\n",
    "\n",
    "# # --- Data Loading ---\n",
    "# file_path = \"S&P Global S1 Transition Risk Data.xlsx\"\n",
    "# df_emissions = pd.read_excel(file_path, sheet_name=\"Table 1\")\n",
    "# df_targets = pd.read_excel(file_path, sheet_name=\"Table 2\")\n",
    "# df_abatement = pd.read_excel(file_path, sheet_name=\"Table 3\")\n",
    "# df_carbon_prices = pd.read_excel(file_path, sheet_name=\"Table 4\")\n",
    "\n",
    "# # --- Clean Table 1: df_emissions (Using Your Cleaning Code) ---\n",
    "# df_emissions.columns = ['uid', 'gics_sector', 'country', 'year', 'scope1_tonnes',\n",
    "#                         'scope2_tonnes', 'unit_production', 'production_volume']\n",
    "# df_emissions = df_emissions.drop_duplicates(subset='uid', keep='first')\n",
    "# df_emissions['country'] = df_emissions['country'].fillna('Unknown').replace({'EUROPE': 'EU'})\n",
    "# df_emissions['year'] = df_emissions['year'].replace({'2,025': 2025, '202five': 2025}).astype(int)\n",
    "# df_emissions['scope1_tonnes'] = pd.to_numeric(df_emissions['scope1_tonnes'], errors='coerce').round()\n",
    "# df_emissions['scope2_tonnes'] = pd.to_numeric(df_emissions['scope2_tonnes'], errors='coerce').round()\n",
    "# df_emissions['production_volume'] = pd.to_numeric(df_emissions['production_volume'], errors='coerce').fillna(0)\n",
    "\n",
    "# # --- Clean Table 2: df_targets (Using Your Cleaning Code) ---\n",
    "# # Clean Table 2: Targets Data\n",
    "# df_targets.columns = ['uid', 'type_of_target', 'reduction_target', 'baseline', 'endline', 'comment']\n",
    "# df_targets['baseline'] = pd.to_numeric(df_targets['baseline'], errors='coerce').astype('Int64')\n",
    "# df_targets['endline'] = pd.to_numeric(df_targets['endline'], errors='coerce').astype('Int64')\n",
    "# # df_targets = df_targets.dropna(subset=['baseline', 'endline'])\n",
    "\n",
    "# df_targets_raw = df_targets.copy()\n",
    "# df_targets.columns = (df_targets.columns.str.strip().str.lower().str.replace(\" \", \"_\"))\n",
    "# YEAR_WORDS = {'twenty-twenty': 2020}\n",
    "\n",
    "# def clean_year(val):\n",
    "#     if pd.isna(val):\n",
    "#         return pd.NA\n",
    "#     s = str(val).strip().lower().replace(',', '')\n",
    "#     if s in YEAR_WORDS:\n",
    "#         return YEAR_WORDS[s]\n",
    "#     return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# df_targets['baseline_year'] = df_targets['baseline'].apply(clean_year).astype('Int64')\n",
    "# df_targets['endline_year'] = df_targets['endline'].apply(clean_year).astype('Int64')\n",
    "# df_targets.drop(columns=['baseline', 'endline'], inplace=True)\n",
    "\n",
    "# def split_reduction(val):\n",
    "#     if pd.isna(val):\n",
    "#         return pd.Series([np.nan, 'unknown', None])\n",
    "#     s = str(val).strip().lower()\n",
    "#     if s == 'forty%' or s == '40%':\n",
    "#         return pd.Series([0.40, 'absolute', '%'])\n",
    "#     m = re.match(r'([0-9]*\\.?[0-9]+)\\s*tco2e/?(.+)?', s)\n",
    "#     if m:\n",
    "#         num = float(m.group(1))\n",
    "#         unit = f\"tCO2e/{m.group(2).strip()}\" if m.group(2) else 'tCO2e'\n",
    "#         return pd.Series([num, 'intensity', unit])\n",
    "#     if s.endswith('%'):\n",
    "#         try:\n",
    "#             num = float(s.replace('%', '')) / 100\n",
    "#             return pd.Series([num, 'absolute', '%'])\n",
    "#         except ValueError:\n",
    "#             return pd.Series([np.nan, 'absolute', '%'])\n",
    "#     try:\n",
    "#         num = float(s)\n",
    "#         if num > 1:\n",
    "#             num = num / 100\n",
    "#         return pd.Series([num, 'absolute', '%'])\n",
    "#     except ValueError:\n",
    "#         return pd.Series([np.nan, 'unknown', None])\n",
    "\n",
    "# df_targets[['reduction_value', 'reduction_type', 'reduction_unit']] = (\n",
    "#     df_targets['reduction_target'].apply(split_reduction)\n",
    "# )\n",
    "# df_targets_clean = (\n",
    "#     df_targets[['uid', 'type_of_target', 'reduction_target', 'reduction_value',\n",
    "#                 'reduction_type', 'reduction_unit', 'baseline_year', 'endline_year', 'comment']]\n",
    "#     .sort_values(['uid', 'type_of_target']).reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # Merge with emissions data\n",
    "# df_merged = df_targets_clean.merge(df_emissions, on=\"uid\", how=\"left\", indicator=True, suffixes=(\"\", \"_em\"))\n",
    "# df_merged = df_merged.rename(columns={\"_merge\": \"merge_status\"})\n",
    "\n",
    "# # --- Clean Table 3: df_abatement ---\n",
    "# df_abatement.columns = ['sector', 'region', 'technology', 'initial_investment_usd_million',\n",
    "#                         'abatement_capacity_tco2e_year', 'abatement_cost_usd_tco2e_year']\n",
    "# df_abatement['region'] = df_abatement['region'].replace({'Europa': 'EU'})\n",
    "# df_abatement['abatement_cost_usd_tco2e_year'] = df_abatement['abatement_cost_usd_tco2e_year'].replace({'eighty': 80}).astype(float)\n",
    "# df_abatement['initial_investment_usd_million'] = df_abatement['initial_investment_usd_million'].fillna(\n",
    "#     df_abatement.groupby('sector')['initial_investment_usd_million'].transform('mean')\n",
    "# )\n",
    "\n",
    "# # --- Clean Table 4: df_carbon_prices ---\n",
    "# df_carbon_prices.columns = ['sector', 'region', 'year', 'scenario', 'carbon_price_usd_tco2e']\n",
    "# df_carbon_prices['region'] = df_carbon_prices['region'].replace({'Europa': 'EU'})\n",
    "# df_carbon_prices['carbon_price_usd_tco2e'] = pd.to_numeric(\n",
    "#     df_carbon_prices['carbon_price_usd_tco2e'], errors='coerce'\n",
    "# ).fillna(df_carbon_prices.groupby('scenario')['carbon_price_usd_tco2e'].transform('mean'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6130c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.reduction_target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06039729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b36639",
   "metadata": {},
   "source": [
    "Merge Emissions and Targets dataframe and clean and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Table 2: Targets\n",
    "# df_targets_raw = df_targets.copy()\n",
    "# df_targets.columns = df_targets.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# # Enhanced year cleaning function\n",
    "# YEAR_WORDS = {\n",
    "#     'twenty-twenty': 2020,\n",
    "#     'twenty twenty': 2020,\n",
    "#     '2,024': 2024,\n",
    "#     '202four': 2024,\n",
    "#     'forty': 40  # For percentage, handled separately in reduction parsing\n",
    "# }\n",
    "\n",
    "# def clean_year(val):\n",
    "#     if pd.isna(val):\n",
    "#         return pd.NA\n",
    "#     s = str(val).strip().lower().replace(',', '')\n",
    "#     if s in YEAR_WORDS:\n",
    "#         return YEAR_WORDS[s]\n",
    "#     try:\n",
    "#         return int(s)\n",
    "#     except ValueError:\n",
    "#         return pd.NA\n",
    "\n",
    "# df_targets['baseline_year'] = df_targets['baseline_year'].apply(clean_year).astype('Int64')\n",
    "# df_targets['endline_year'] = df_targets['endline_year'].apply(clean_year).fillna(2050).astype('Int64')  # Assume 2050 if endline missing\n",
    "# # df_targets.drop(columns=['baseline_year', 'endline_year'], inplace=True) \n",
    "\n",
    "# def split_reduction(val):\n",
    "#     if pd.isna(val):\n",
    "#         return pd.Series([np.nan, 'unknown', None])\n",
    "#     s = str(val).strip().lower()\n",
    "#     if s == 'forty%' or s == '40%':\n",
    "#         return pd.Series([0.40, 'absolute', '%'])\n",
    "#     m = re.match(r'([0-9]*\\.?[0-9]+)\\s*tco2e/?(.+)?', s)\n",
    "#     if m:\n",
    "#         num = float(m.group(1))\n",
    "#         unit = f\"tCO2e/{m.group(2).strip()}\" if m.group(2) else 'tCO2e'\n",
    "#         return pd.Series([num, 'intensity', unit])\n",
    "#     if s.endswith('%'):\n",
    "#         try:\n",
    "#             num = float(s.replace('%', '')) / 100\n",
    "#             return pd.Series([num, 'absolute', '%'])\n",
    "#         except ValueError:\n",
    "#             return pd.Series([np.nan, 'absolute', '%'])\n",
    "#     try:\n",
    "#         num = float(s)\n",
    "#         if num > 1:\n",
    "#             num = num / 100\n",
    "#         return pd.Series([num, 'absolute', '%'])\n",
    "#     except ValueError:\n",
    "#         return pd.Series([np.nan, 'unknown', None])\n",
    "\n",
    "# df_targets[['reduction_value', 'reduction_type', 'reduction_unit']] = df_targets['reduction_target'].apply(split_reduction)\n",
    "# df_targets_clean = df_targets[\n",
    "#     ['uid', 'type_of_target', 'reduction_target', 'reduction_value', 'reduction_type', 'reduction_unit', 'baseline_year', 'endline_year', 'comment']\n",
    "# ].sort_values(['uid', 'type_of_target']).reset_index(drop=True)\n",
    "# #\n",
    "# # Keep rows that actually *have* a reduction value\n",
    "# df_targets_clean = (\n",
    "#     df_targets\n",
    "#       .dropna(subset=[\"reduction_value\"])\n",
    "#       .sort_values([\"uid\", \"type_of_target\"])\n",
    "#       .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # ======================================================\n",
    "# # 4. Merge with emissions data\n",
    "# # ======================================================\n",
    "# df_merged = (\n",
    "#     df_targets_clean\n",
    "#       .merge(df_emissions,\n",
    "#              on=\"uid\",\n",
    "#              how=\"left\",\n",
    "#              indicator=True,\n",
    "#              suffixes=(\"_t\", \"_em\"))\n",
    "#       .rename(columns={\"_merge\": \"merge_status\"})\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d84ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fec8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bff464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for uid equal C011 \n",
    "# df_filtered = df_merged[df_merged['uid'] == 'C011'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3107472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7814003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Clean and Prepare Abatement Table ---\n",
    "# # Rename columns\n",
    "# df_abatement.columns = [\n",
    "#     'sector', 'region', 'technology',\n",
    "#     'initial_investment_usd_million',\n",
    "#     'abatement_capacity_tco2e_year',\n",
    "#     'abatement_cost_usd_tco2e_year'\n",
    "# ]\n",
    "\n",
    "# # Standardize region names\n",
    "# df_abatement['region'] = df_abatement['region'].replace({'Europa': 'EU'})\n",
    "\n",
    "# # Convert numeric fields and impute missing values with sector means\n",
    "# for col in ['abatement_cost_usd_tco2e_year', 'initial_investment_usd_million']:\n",
    "#     df_abatement[col] = pd.to_numeric(df_abatement[col], errors='coerce')\n",
    "#     df_abatement[col] = df_abatement[col].fillna(\n",
    "#         df_abatement.groupby('sector')[col].transform('mean')\n",
    "#     ).round(2)\n",
    "\n",
    "# # --- Clean and Prepare Carbon Prices Table ---\n",
    "# # Rename columns\n",
    "# df_carbon_prices.columns = ['sector', 'region', 'year', 'scenario', 'carbon_price_usd_tco2e']\n",
    "\n",
    "# # Standardize region names\n",
    "# df_carbon_prices['region'] = df_carbon_prices['region'].replace({'Europa': 'EU'})\n",
    "\n",
    "# # Convert carbon prices and fill missing by scenario+sector group\n",
    "# df_carbon_prices['carbon_price_usd_tco2e'] = pd.to_numeric(\n",
    "#     df_carbon_prices['carbon_price_usd_tco2e'], errors='coerce'\n",
    "# )\n",
    "# df_carbon_prices['carbon_price_usd_tco2e'] = df_carbon_prices['carbon_price_usd_tco2e'].fillna(\n",
    "#     df_carbon_prices.groupby(['scenario', 'sector'])['carbon_price_usd_tco2e'].transform('mean')\n",
    "# ).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.reduction_unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0453552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.head(2).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged[df_merged['reduction_unit'] == 'tCO2e/m2 building'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_clean.reduction_value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c58d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def project_emissions(\n",
    "    row: pd.Series,\n",
    "    years: np.ndarray = np.arange(2025, 2051),\n",
    "    scenarios: dict | None = None,\n",
    "    interpolation_method: str = \"linear\",\n",
    "    *,\n",
    "    targets_df: pd.DataFrame = df_targets_clean,   # injected once, stays global\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Project Scope-1 & Scope-2 emissions for ONE company, 2025-2050.\n",
    "\n",
    "    Assumptions revised (July 2025):\n",
    "    • `scope1_tonnes`, `scope2_tonnes`, `baseline_production_volume`\n",
    "      already represent the company’s *actual 2025* values.\n",
    "    • No growth is applied to bring earlier-baseline figures up to 2025.\n",
    "    • Reductions (absolute or intensity) start in 2026 or later.\n",
    "    \"\"\"\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    # A.  Filter out Scope-3-only rows\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    if \"scope 3\" in str(row.get(\"type_of_target\", \"\")).lower():\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    uid          = row[\"uid\"]\n",
    "    tgt_scope    = row[\"type_of_target\"]            # \"Scope 1\" / \"Scope 2\" / \"Direct\"\n",
    "    base_prod    = row.get(\"baseline_production_volume\", 0)\n",
    "    g_rate       = row.get(\"production_growth_rate\", 0.0)\n",
    "\n",
    "    # 2025 anchor tonnages (already correct and *static*)\n",
    "    s1_2025 = row.get(\"scope1_tonnes\")\n",
    "    s2_2025 = row.get(\"scope2_tonnes\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    # B.  Fallbacks if 2025 tonnages are missing\n",
    "    #     (copy baseline value *as-is* – NO growth)\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    need_s1 = not tgt_scope.lower().startswith(\"scope 2\")\n",
    "    need_s2 = not tgt_scope.lower().startswith(\"scope 1\")\n",
    "\n",
    "    if pd.isna(s1_2025) and need_s1:\n",
    "        s1_2025 = row.get(\"baseline_scope1_tonnes\")\n",
    "        if pd.isna(s1_2025) and base_prod > 0:\n",
    "            s1_2025 = row.get(\"baseline_scope1_intensity\") * base_prod\n",
    "\n",
    "    if pd.isna(s2_2025) and need_s2:\n",
    "        s2_2025 = row.get(\"baseline_scope2_tonnes\")\n",
    "        if pd.isna(s2_2025) and base_prod > 0:\n",
    "            s2_2025 = row.get(\"baseline_scope2_intensity\") * base_prod\n",
    "\n",
    "    # must now have every required 2025 anchor\n",
    "    if (need_s1 and pd.isna(s1_2025)) or (need_s2 and pd.isna(s2_2025)):\n",
    "        raise ValueError(f\"{uid}: missing 2025 Scope-1/2 values required for projection.\")\n",
    "\n",
    "    # replace unused scopes with zero\n",
    "    s1_2025 = 0 if pd.isna(s1_2025) else float(s1_2025)\n",
    "    s2_2025 = 0 if pd.isna(s2_2025) else float(s2_2025)\n",
    "\n",
    "    # keep a true 2025 production anchor\n",
    "    prod_2025 = float(base_prod)\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    # C.  Pick this company’s targets (same uid + scope)\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    tgt_mask = targets_df[\"uid\"].eq(uid)\n",
    "    if tgt_scope.lower().startswith(\"scope 1\"):\n",
    "        tgt_mask &= targets_df[\"type_of_target\"].str.startswith(\"Scope 1\")\n",
    "    elif tgt_scope.lower().startswith(\"scope 2\"):\n",
    "        tgt_mask &= targets_df[\"type_of_target\"].str.startswith(\"Scope 2\")\n",
    "\n",
    "    targets = (\n",
    "        targets_df.loc[tgt_mask]\n",
    "                  .dropna(subset=[\"reduction_value\", \"endline_year\"])\n",
    "                  .assign(endline_year=lambda d: d[\"endline_year\"].astype(int))\n",
    "                  .query(\"endline_year > 2025\")\n",
    "                  .copy()\n",
    "    )\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    # D.  Default scenario if none given\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    if scenarios is None:\n",
    "        scenarios = {\"default\": {\"growth_rate\": g_rate,\n",
    "                                 \"interpolation\": interpolation_method}}\n",
    "\n",
    "    # helper for absolute-reduction curves\n",
    "    def _apply_absolute(base_val, reduction, n_years, yr, interp):\n",
    "        tgt_val = base_val * (1 - reduction)\n",
    "        drop    = base_val - tgt_val\n",
    "        if interp == \"linear\":\n",
    "            frac = min((yr - 2025) / n_years, 1)\n",
    "            return base_val - drop * frac\n",
    "        elif interp == \"exponential\":\n",
    "            r = (1 - reduction) ** (1 / n_years)\n",
    "            return base_val * r ** (yr - 2025) if yr <= 2025 + n_years else tgt_val\n",
    "        elif interp == \"s_curve\":\n",
    "            k  = 9.21 / n_years\n",
    "            t0 = 2025 + n_years / 2\n",
    "            frac = 1 / (1 + np.exp(-k * (yr - t0))) if yr <= 2025 + n_years else 1\n",
    "            return base_val - drop * frac\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown interpolation '{interp}'\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    # E.  Build pathway rows\n",
    "    # ───────────────────────────────────────────────────────────────\n",
    "    rows = []\n",
    "\n",
    "    for scen, cfg in scenarios.items():\n",
    "        g_r   = cfg.get(\"growth_rate\", g_rate)\n",
    "        interp= cfg.get(\"interpolation\", interpolation_method)\n",
    "\n",
    "        for yr in years:\n",
    "            s1, s2 = s1_2025, s2_2025     # reset every year\n",
    "\n",
    "            # apply all targets that matter\n",
    "            for _, tgt in targets.iterrows():\n",
    "                nY = tgt[\"endline_year\"] - 2025\n",
    "                if nY <= 0:\n",
    "                    continue\n",
    "\n",
    "                red_val = tgt[\"reduction_value\"]\n",
    "                red_typ = tgt[\"reduction_type\"]\n",
    "                t_scope = tgt[\"type_of_target\"]\n",
    "\n",
    "                # ----- absolute reduction ----------------------------------\n",
    "                if red_typ == \"absolute\":\n",
    "                    if t_scope.startswith(\"Scope 1\"):\n",
    "                        s1 = _apply_absolute(s1_2025, red_val, nY, yr, interp)\n",
    "                    elif t_scope.startswith(\"Scope 2\"):\n",
    "                        s2 = _apply_absolute(s2_2025, red_val, nY, yr, interp)\n",
    "                    else:  # \"Direct\"\n",
    "                        T0 = s1_2025 + s2_2025\n",
    "                        Tt = _apply_absolute(T0, red_val, nY, yr, interp)\n",
    "                        if T0:\n",
    "                            s1 = Tt * s1_2025 / T0\n",
    "                            s2 = Tt * s2_2025 / T0\n",
    "\n",
    "                # ----- intensity reduction --------------------------------\n",
    "                else:\n",
    "                    if prod_2025 == 0:      # nothing to scale\n",
    "                        continue\n",
    "                    prod_yr = (\n",
    "                        prod_2025 if yr == 2025\n",
    "                        else prod_2025 * (1 + g_r) ** (yr - 2025)\n",
    "                    )\n",
    "\n",
    "                    def _apply_intensity(base_I):\n",
    "                        return _apply_absolute(base_I, red_val, nY, yr, interp)\n",
    "\n",
    "                    if t_scope.startswith(\"Scope 1\"):\n",
    "                        I0 = s1_2025 / prod_2025\n",
    "                        s1 = _apply_intensity(I0) * prod_yr\n",
    "                    elif t_scope.startswith(\"Scope 2\"):\n",
    "                        I0 = s2_2025 / prod_2025\n",
    "                        s2 = _apply_intensity(I0) * prod_yr\n",
    "                    else:\n",
    "                        I0 = (s1_2025 + s2_2025) / prod_2025\n",
    "                        It = _apply_intensity(I0) * prod_yr\n",
    "                        frac = s1_2025 / (s1_2025 + s2_2025) if s1_2025 + s2_2025 else 0\n",
    "                        s1, s2 = It * frac, It * (1 - frac)\n",
    "\n",
    "            # what counts toward the company’s own KPI?\n",
    "            if tgt_scope.lower().startswith(\"scope 1\"):\n",
    "                tgt_em = round(s1)\n",
    "            elif tgt_scope.lower().startswith(\"scope 2\"):\n",
    "                tgt_em = round(s2)\n",
    "            else:  # \"Direct\"\n",
    "                tgt_em = round(s1 + s2)\n",
    "\n",
    "            rows.append({\n",
    "                \"uid\": uid,\n",
    "                \"gics_sector\": row[\"gics_sector\"],\n",
    "                \"country\": row[\"country\"],\n",
    "                \"type_of_target\": tgt_scope,\n",
    "                \"year\": yr,\n",
    "                \"scope1_tonnes\": round(s1),\n",
    "                \"scope2_tonnes\": round(s2),\n",
    "                \"targeted_emissions\": tgt_em,\n",
    "                \"scenario\": scen,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af27059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def project_emissions(\n",
    "#     row: pd.Series,\n",
    "#     years: np.ndarray = np.arange(2025, 2051),\n",
    "#     scenarios: dict | None = None,\n",
    "#     interpolation_method: str = \"linear\",\n",
    "#     *,\n",
    "#     targets_df: pd.DataFrame = df_targets_clean,   # pass once, stays global\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Project Scope-1 & Scope-2 emissions for a single company, 2025-2050.\n",
    "\n",
    "#     * Skips rows whose target is Scope 3.\n",
    "#     * If 2025 values are missing, grows baseline-year data forward to 2025.\n",
    "#     * `targeted_emissions` == Scope 1, Scope 2, or sum, depending on the row’s\n",
    "#       own target scope.\n",
    "#     \"\"\"\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 0. Skip Scope-3 pathways entirely\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     if \"scope 3\" in str(row[\"type_of_target\"]).lower():\n",
    "#         return pd.DataFrame()          # silently drop Scope-3 rows\n",
    "\n",
    "#     uid          = row[\"uid\"]\n",
    "#     tgt_scope    = row[\"type_of_target\"]      # e.g. \"Scope 2\", \"Direct\"\n",
    "#     # baseline_y   = int(row[\"baseline_year\"])\n",
    "#     baseline_y_raw = row.get(\"baseline_year\")\n",
    "#     if pd.isna(baseline_y_raw):\n",
    "#         baseline_y = 2025          # or raise / skip\n",
    "#     else:\n",
    "#         baseline_y = int(baseline_y_raw)\n",
    "#     base_prod    = row.get(\"baseline_production_volume\", 0)\n",
    "#     g_rate       = row.get(\"production_growth_rate\", 0.0)\n",
    "\n",
    "#     # pull possible 2025 values from the row ----------------------------\n",
    "#     s1_2025 = row.get(\"scope1_tonnes\")\n",
    "#     s2_2025 = row.get(\"scope2_tonnes\")\n",
    "\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 1. If a 2025 scope is required but missing, derive it from baseline\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     need_s1 = not tgt_scope.lower().startswith(\"scope 2\")   # Scope-1 or Direct\n",
    "#     need_s2 = not tgt_scope.lower().startswith(\"scope 1\")   # Scope-2 or Direct\n",
    "\n",
    "#     # -- helper to grow absolute numbers or intensities to 2025\n",
    "#     def _grow_to_2025(value, years_diff):\n",
    "#         \"\"\"Apply compound growth (if any) to bring a baseline value to 2025.\"\"\"\n",
    "#         return value * (1 + g_rate) ** years_diff\n",
    "\n",
    "#     # grow Scope-1 -------------------------------------------------------\n",
    "#     if pd.isna(s1_2025) and need_s1:\n",
    "#         s1_baseline = row.get(\"baseline_scope1_tonnes\")\n",
    "#         if pd.notna(s1_baseline):\n",
    "#             s1_2025 = _grow_to_2025(s1_baseline, 2025 - baseline_y)\n",
    "#         else:\n",
    "#             # try intensity if baseline production is present\n",
    "#             if base_prod > 0 and pd.notna(row.get(\"baseline_scope1_intensity\")):\n",
    "#                 s1_2025 = (\n",
    "#                     row[\"baseline_scope1_intensity\"]\n",
    "#                     * _grow_to_2025(base_prod, 2025 - baseline_y)\n",
    "#                 )\n",
    "#     # grow Scope-2 -------------------------------------------------------\n",
    "#     if pd.isna(s2_2025) and need_s2:\n",
    "#         s2_baseline = row.get(\"baseline_scope2_tonnes\")\n",
    "#         if pd.notna(s2_baseline):\n",
    "#             s2_2025 = _grow_to_2025(s2_baseline, 2025 - baseline_y)\n",
    "#         else:\n",
    "#             if base_prod > 0 and pd.notna(row.get(\"baseline_scope2_intensity\")):\n",
    "#                 s2_2025 = (\n",
    "#                     row[\"baseline_scope2_intensity\"]\n",
    "#                     * _grow_to_2025(base_prod, 2025 - baseline_y)\n",
    "#                 )\n",
    "\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 2. Validate that we now have the required 2025 baselines\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     if (need_s1 and pd.isna(s1_2025)) or (need_s2 and pd.isna(s2_2025)):\n",
    "#         raise ValueError(\n",
    "#             f\"Company {uid}: missing 2025 value for \"\n",
    "#             f\"{'Scope 1' if need_s1 and pd.isna(s1_2025) else ''}\"\n",
    "#             f\"{' / ' if need_s1 and need_s2 else ''}\"\n",
    "#             f\"{'Scope 2' if need_s2 and pd.isna(s2_2025) else ''}\"\n",
    "#         )\n",
    "\n",
    "#     # For unused scopes, replace NaN with zero so maths works cleanly\n",
    "#     s1_2025 = 0 if pd.isna(s1_2025) else s1_2025\n",
    "#     s2_2025 = 0 if pd.isna(s2_2025) else s2_2025\n",
    "\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 3. Select only the targets relevant to this row’s scope\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     tgt_mask = targets_df[\"uid\"].eq(uid)\n",
    "#     if tgt_scope.lower().startswith(\"scope 1\"):\n",
    "#         tgt_mask &= targets_df[\"type_of_target\"].str.startswith(\"Scope 1\")\n",
    "#     elif tgt_scope.lower().startswith(\"scope 2\"):\n",
    "#         tgt_mask &= targets_df[\"type_of_target\"].str.startswith(\"Scope 2\")\n",
    "#     # else Direct → keep all\n",
    "#     # targets = targets_df.loc[tgt_mask].copy()\n",
    "# #     targets = (\n",
    "# #     targets_df.loc[tgt_mask]          # keep relevant scope\n",
    "# #               .dropna(subset=[\"reduction_value\"])   # ← NEW LINE\n",
    "# #               .copy()\n",
    "# # )\n",
    "#     targets = (\n",
    "#     targets_df.loc[tgt_mask]\n",
    "#               .dropna(subset=[\"reduction_value\", \"endline_year\"])\n",
    "#               .assign(endline_year=lambda d: d[\"endline_year\"].astype(int))\n",
    "#               .query(\"endline_year > 2025\")\n",
    "#               .copy()\n",
    "# )\n",
    "\n",
    "\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 4. Build default scenario if none supplied\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     if scenarios is None:\n",
    "#         scenarios = {\"default\": {\"growth_rate\": g_rate,\n",
    "#                                  \"interpolation\": interpolation_method}}\n",
    "\n",
    "#     # ---------- helper for absolute reduction -------------------------\n",
    "#     def _apply_absolute(base_val, reduction, n_years, yr, interp):\n",
    "#         target_val = base_val * (1 - reduction)\n",
    "#         Δ = base_val - target_val\n",
    "#         if interp == \"linear\":\n",
    "#             applied = min((yr-2025) / n_years, 1) * Δ\n",
    "#             return max(0, base_val - applied)\n",
    "#         elif interp == \"exponential\":\n",
    "#             r = (1 - reduction) ** (1 / n_years)\n",
    "#             return base_val * r ** (yr-2025) if yr <= 2025+n_years else target_val\n",
    "#         elif interp == \"s_curve\":\n",
    "#             k = 9.21 / n_years\n",
    "#             t0 = 2025 + n_years/2\n",
    "#             frac = 1 / (1 + np.exp(-k*(yr-t0))) if yr <= 2025+n_years else 1\n",
    "#             return base_val - Δ*frac\n",
    "#         raise ValueError(\"Unknown interpolation\")\n",
    "\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     # 5. Year-by-year projection\n",
    "#     # ------------------------------------------------------------------ #\n",
    "#     out = []\n",
    "\n",
    "#     for scen_name, scen_cfg in scenarios.items():\n",
    "#         g_r   = scen_cfg.get(\"growth_rate\", g_rate)\n",
    "#         interp= scen_cfg.get(\"interpolation\", interpolation_method)\n",
    "\n",
    "#         for yr in years:\n",
    "#             # start fresh from baseline each year\n",
    "#             s1 = s1_2025\n",
    "#             s2 = s2_2025\n",
    "\n",
    "#             # apply every relevant target\n",
    "#             for _, tgt in targets.iterrows():\n",
    "#                 nY = tgt[\"endline_year\"] - 2025\n",
    "#                 if nY <= 0:\n",
    "#                     continue\n",
    "\n",
    "#                 red_val = tgt[\"reduction_value\"]\n",
    "#                 red_typ = tgt[\"reduction_type\"]\n",
    "#                 t_scope = tgt[\"type_of_target\"]\n",
    "\n",
    "#                 if red_typ == \"absolute\":\n",
    "#                     if t_scope.startswith(\"Scope 1\"):\n",
    "#                         s1 = _apply_absolute(s1_2025, red_val, nY, yr, interp)\n",
    "#                     elif t_scope.startswith(\"Scope 2\"):\n",
    "#                         s2 = _apply_absolute(s2_2025, red_val, nY, yr, interp)\n",
    "#                     else:  # Direct\n",
    "#                         T0 = s1_2025 + s2_2025\n",
    "#                         Tt = _apply_absolute(T0, red_val, nY, yr, interp)\n",
    "#                         if T0:\n",
    "#                             s1 = Tt * s1_2025 / T0\n",
    "#                             s2 = Tt * s2_2025 / T0\n",
    "#                 else:  # intensity target\n",
    "#                     prod_yr = base_prod * (1+g_r)**(yr-2025)\n",
    "#                     if prod_yr == 0:\n",
    "#                         continue\n",
    "\n",
    "#                     def _apply_intensity(base_I):\n",
    "#                         return _apply_absolute(base_I, red_val, nY, yr, interp)\n",
    "\n",
    "#                     if t_scope.startswith(\"Scope 1\"):\n",
    "#                         I0 = s1_2025 / base_prod\n",
    "#                         s1 = _apply_intensity(I0) * prod_yr\n",
    "#                     elif t_scope.startswith(\"Scope 2\"):\n",
    "#                         I0 = s2_2025 / base_prod\n",
    "#                         s2 = _apply_intensity(I0) * prod_yr\n",
    "#                     else:\n",
    "#                         I0 = (s1_2025+s2_2025) / base_prod\n",
    "#                         It = _apply_intensity(I0) * prod_yr\n",
    "#                         frac = s1_2025 / (s1_2025 + s2_2025) if s1_2025+s2_2025 else 0\n",
    "#                         s1, s2 = It*frac, It*(1-frac)\n",
    "\n",
    "#             # choose what counts toward the company’s own target\n",
    "#             if tgt_scope.lower().startswith(\"scope 1\"):\n",
    "#                 tgt_em = round(s1)\n",
    "#             elif tgt_scope.lower().startswith(\"scope 2\"):\n",
    "#                 tgt_em = round(s2)\n",
    "#             else:\n",
    "#                 tgt_em = round(s1 + s2)\n",
    "\n",
    "#             out.append({\n",
    "#                 \"uid\": uid,\n",
    "#                 \"gics_sector\": row[\"gics_sector\"],\n",
    "#                 \"country\": row[\"country\"],\n",
    "#                 \"type_of_target\": tgt_scope,\n",
    "#                 \"year\": yr,\n",
    "#                 \"scope1_tonnes\": round(s1),\n",
    "#                 \"scope2_tonnes\": round(s2),\n",
    "#                 \"targeted_emissions\": tgt_em,\n",
    "#                 \"scenario\": scen_name,\n",
    "#             })\n",
    "\n",
    "#     return pd.DataFrame(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c850cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.reduction_value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bee1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected scenarios dictionary\n",
    "scenarios = {\n",
    "    'low': {'growth_rate': 0.0, 'interpolation': 'linear'},\n",
    "    'med': {'growth_rate': 0.01, 'interpolation': 'linear'},\n",
    "    'high': {'growth_rate': 0.02, 'interpolation': 'linear'},\n",
    "    # 's_curve_low': {'growth_rate': 0.0, 'interpolation': 's_curve'},\n",
    "    # 's_curve_med': {'growth_rate': 0.01, 'interpolation': 's_curve'},\n",
    "    # 's_curve_high': {'growth_rate': 0.02, 'interpolation': 's_curve'}\n",
    "}\n",
    "\n",
    "# Run the projection\n",
    "# emissions_paths = project_emissions(df_merged, scenarios=scenarios)\n",
    "# Apply the function and concatenate results\n",
    "emissions_paths_list = df_merged.apply(\n",
    "    lambda row: project_emissions(row, scenarios=scenarios), axis=1\n",
    ").tolist()\n",
    "emissions_paths = pd.concat(emissions_paths_list, ignore_index=True)\n",
    "\n",
    "# Define mappings\n",
    "growth_rate_mapping = {\n",
    "    'low': 0.0,\n",
    "    'med': 0.01,\n",
    "    'high': 0.02,\n",
    "    # 's_curve_low': 0.0,\n",
    "    # 's_curve_med': 0.01,\n",
    "    # 's_curve_high': 0.02\n",
    "}\n",
    "\n",
    "interpolation_mapping = {\n",
    "    'low': 'linear',\n",
    "    'med': 'linear',\n",
    "    'high': 'linear',\n",
    "    # 's_curve_low': 's_curve',\n",
    "    # 's_curve_med': 's_curve',\n",
    "    # 's_curve_high': 's_curve'\n",
    "}\n",
    "\n",
    "# Add columns\n",
    "emissions_paths['growth_rate'] = emissions_paths['scenario'].map(growth_rate_mapping)\n",
    "emissions_paths['interpolation_method'] = emissions_paths['scenario'].map(interpolation_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8c7a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>country</th>\n",
       "      <th>type_of_target</th>\n",
       "      <th>year</th>\n",
       "      <th>scope1_tonnes</th>\n",
       "      <th>scope2_tonnes</th>\n",
       "      <th>targeted_emissions</th>\n",
       "      <th>scenario</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>interpolation_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2025</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1070000</td>\n",
       "      <td>1070000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2026</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1046588</td>\n",
       "      <td>1046588</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2027</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1023177</td>\n",
       "      <td>1023177</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2028</td>\n",
       "      <td>21510000</td>\n",
       "      <td>999765</td>\n",
       "      <td>999765</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2029</td>\n",
       "      <td>21510000</td>\n",
       "      <td>976354</td>\n",
       "      <td>976354</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  gics_sector country type_of_target  year  scope1_tonnes  \\\n",
       "0  C001  Real Estate  Global        Scope 2  2025       21510000   \n",
       "1  C001  Real Estate  Global        Scope 2  2026       21510000   \n",
       "2  C001  Real Estate  Global        Scope 2  2027       21510000   \n",
       "3  C001  Real Estate  Global        Scope 2  2028       21510000   \n",
       "4  C001  Real Estate  Global        Scope 2  2029       21510000   \n",
       "\n",
       "   scope2_tonnes  targeted_emissions scenario  growth_rate  \\\n",
       "0        1070000             1070000      low          0.0   \n",
       "1        1046588             1046588      low          0.0   \n",
       "2        1023177             1023177      low          0.0   \n",
       "3         999765              999765      low          0.0   \n",
       "4         976354              976354      low          0.0   \n",
       "\n",
       "  interpolation_method  \n",
       "0               linear  \n",
       "1               linear  \n",
       "2               linear  \n",
       "3               linear  \n",
       "4               linear  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows still have NA?\n",
    "df_merged[\"reduction_value\"].isna().sum()\n",
    "\n",
    "# Show a couple of offenders\n",
    "df_merged.loc[df_merged[\"reduction_value\"].isna(), [\"uid\", \"reduction_target\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e6311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.query(\"uid == 'C999'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ce633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the emissions_paths DataFrame to a CSV file\n",
    "emissions_paths.to_csv(\"emissions_paths.csv\", index=False)\n",
    "# export df_merged to a CSV file\n",
    "df_merged.to_csv(\"df_merged.csv\", index=False)\n",
    "# export df_emissions to a CSV file\n",
    "df_emissions.to_csv(\"df_emissions.csv\", index=False)\n",
    "# export df_targets_clean to a CSV file\n",
    "df_targets_clean.to_csv(\"df_targets_clean.csv\", index=False)\n",
    "# export df_abatement to a CSV file\n",
    "df_abatement.to_csv(\"df_abatement.csv\", index=False)\n",
    "# export df_carbon_prices to a CSV file\n",
    "df_carbon_prices.to_csv(\"df_carbon_prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887177d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876777b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle all relevant target types properly\n",
    "# def get_targeted_emissions(row):\n",
    "#     if row['type_of_target'] == 'Scope 1':\n",
    "#         return row['scope1_tonnes']\n",
    "#     elif row['type_of_target'] == 'Scope 2':\n",
    "#         return row['scope2_tonnes']\n",
    "#     elif row['type_of_target'] in ['Direct', 'Scope 2 and other']:\n",
    "#         return row['scope1_tonnes'] + row['scope2_tonnes']\n",
    "#     else:\n",
    "#         return np.nan\n",
    "\n",
    "# emissions_paths['targeted_emissions'] = emissions_paths.apply(get_targeted_emissions, axis=1)\n",
    "\n",
    "# # Keep only valid rows\n",
    "# df_filtered = emissions_paths[~emissions_paths['targeted_emissions'].isna()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 1. Prepare buckets\n",
    "# sorted_uids = matrix['pct_reduction'].sort_values()\n",
    "# buckets = {\n",
    "#     'Top 5': sorted_uids.index[-5:],\n",
    "#     'Mid 5': sorted_uids.index[25:30],\n",
    "#     'Bottom 5': sorted_uids.index[:5],\n",
    "# }\n",
    "\n",
    "# # 2. Plot\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(12, 14), sharex=True, sharey=True)\n",
    "\n",
    "# for ax, (label, uids) in zip(axes, buckets.items()):\n",
    "#     subset = df_filtered[df_filtered['uid'].isin(uids)]\n",
    "#     sns.lineplot(\n",
    "#         data=subset,\n",
    "#         x='year',\n",
    "#         y='targeted_emissions',\n",
    "#         hue='uid',\n",
    "#         style='uid',\n",
    "#         markers=True,\n",
    "#         dashes=False,\n",
    "#         ax=ax\n",
    "#     )\n",
    "#     ax.set_title(f'{label} Reducers')\n",
    "#     ax.set_ylabel('Emissions (tCO₂e)')\n",
    "#     ax.legend(title='Company', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# axes[-1].set_xlabel('Year')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.interpolation_method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3546055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d251833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Pivot out 2025 & 2050, compute percent reduction **per scope**\n",
    "# df_pr = (\n",
    "#     emissions_paths\n",
    "#     .loc[emissions_paths['year'].isin([2025, 2050]), \n",
    "#          ['uid','gics_sector','country','scope1_tonnes','scope2_tonnes','year']]\n",
    "#     .pivot_table(\n",
    "#         index=['uid','gics_sector','country'],\n",
    "#         columns='year',\n",
    "#         values=['scope1_tonnes','scope2_tonnes']\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Flatten MultiIndex columns\n",
    "# df_pr.columns = [f\"{scope}_{yr}\" for scope, yr in df_pr.columns]\n",
    "# df_pr = df_pr.dropna()\n",
    "\n",
    "# # Compute reductions\n",
    "# df_pr['pct_red_1'] = (df_pr['scope1_tonnes_2025'] - df_pr['scope1_tonnes_2050']) / df_pr['scope1_tonnes_2025'] * 100\n",
    "# df_pr['pct_red_2'] = (df_pr['scope2_tonnes_2025'] - df_pr['scope2_tonnes_2050']) / df_pr['scope2_tonnes_2025'] * 100\n",
    "\n",
    "# # Reset for plotting\n",
    "# df_pr = df_pr.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad333350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # A1. Mean % Reduction by Country: Scope 1\n",
    "# plt.figure(figsize=(10,4))\n",
    "# sns.barplot(\n",
    "#     data=df_pr, x='country', y='pct_red_1',\n",
    "#     estimator='mean', ci=None, order=df_pr.groupby('country')['pct_red_1'].mean().sort_values().index\n",
    "# )\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.title('Mean Scope 1 % Reduction by Country (2025→2050)')\n",
    "# plt.ylabel('% Reduction')\n",
    "# plt.xlabel('')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # A2. Mean % Reduction by Country: Scope 2\n",
    "# plt.figure(figsize=(10,4))\n",
    "# sns.barplot(\n",
    "#     data=df_pr, x='country', y='pct_red_2',\n",
    "#     estimator='mean', ci=None, order=df_pr.groupby('country')['pct_red_2'].mean().sort_values().index\n",
    "# )\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.title('Mean Scope 2 % Reduction by Country (2025→2050)')\n",
    "# plt.ylabel('% Reduction')\n",
    "# plt.xlabel('')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b113707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_trends = (\n",
    "#     emissions_paths\n",
    "#     .groupby(['country','year'])[['scope1_tonnes','scope2_tonnes']]\n",
    "#     .mean()\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# # B1. Scope 1 Trajectories\n",
    "# plt.figure(figsize=(10,4))\n",
    "# sns.lineplot(\n",
    "#     data=country_trends, x='year', y='scope1_tonnes',\n",
    "#     hue='country', marker='o'\n",
    "# )\n",
    "# plt.title('Avg Scope 1 Emissions by Country (2025–2050)')\n",
    "# plt.ylabel('Emissions (tCO₂e)')\n",
    "# plt.legend(bbox_to_anchor=(1.02,1), loc='upper left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # B2. Scope 2 Trajectories\n",
    "# plt.figure(figsize=(10,4))\n",
    "# sns.lineplot(\n",
    "#     data=country_trends, x='year', y='scope2_tonnes',\n",
    "#     hue='country', marker='o'\n",
    "# )\n",
    "# plt.title('Avg Scope 2 Emissions by Country (2025–2050)')\n",
    "# plt.ylabel('Emissions (tCO₂e)')\n",
    "# plt.legend(bbox_to_anchor=(1.02,1), loc='upper left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.type_of_target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7abfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306a40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.uid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"emissions_targets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5fa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0634b7c4",
   "metadata": {},
   "source": [
    "Estimate Carbon pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for negative or zero values in the 'carbon_price_usd_tco2e' column\n",
    "# negative_prices = df_carbon_prices['carbon_price_usd_tco2e'] <= 0\n",
    "# print(negative_prices)  # Returns a boolean Series\n",
    "# print(negative_prices.any())  # Returns True if any value is <= 0\n",
    "# print(df_carbon_prices[negative_prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngf5_eu_carbon_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf5_global_carbon_prices = pd.read_csv(\"/Users/tarunluthra/Documents/SPglobal/ngfs_global_snapshot_1750868451.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf71b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf5_global_carbon_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2093b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf5_eu_carbon_prices = pd.read_csv(\"/Users/tarunluthra/Documents/SPglobal/ngfs_snapshot_1750868525.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d43e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngf5_eu_carbon_prices.Scenario.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbc6ef",
   "metadata": {},
   "source": [
    "NGF5 and CAGR model for carbon pricing for different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2913947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_prices_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_prices_full.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73eb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7131135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.sector.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon_prices.sector.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf136b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b0bb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/9_7wh6ps1354b6glt9mst87m0000gn/T/ipykernel_40275/3554481954.py:27: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the function to project carbon prices using linear regression\n",
    "def project_carbon_price(group):\n",
    "    # Fill missing carbon prices with the median of the group\n",
    "    group['carbon_price_usd_tco2e_filled'] = group['carbon_price_usd_tco2e'].fillna(group['carbon_price_usd_tco2e'].median())\n",
    "    group_filled = group.dropna(subset=['carbon_price_usd_tco2e_filled'])\n",
    "    if len(group_filled) >= 2:\n",
    "        # Prepare data for linear regression\n",
    "        X = group_filled['year'].values.reshape(-1, 1)\n",
    "        y = group_filled['carbon_price_usd_tco2e_filled'].values\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        # Predict prices from 2025 to 2050\n",
    "        years = np.arange(2025, 2051)\n",
    "        predictions = model.predict(years.reshape(-1, 1))\n",
    "        return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': predictions})\n",
    "    else:\n",
    "        # Return NaN predictions if insufficient data\n",
    "        years = np.arange(2025, 2051)\n",
    "        return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': [np.nan] * len(years)})\n",
    "\n",
    "# Assuming df_carbon_prices is a DataFrame with columns: sector, region, scenario, year, carbon_price_usd_tco2e\n",
    "# Apply the projection to get carbon_prices_full\n",
    "carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n",
    "carbon_prices_full = carbon_prices_full.sort_values(by=['sector', 'region', 'scenario', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17042d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/9_7wh6ps1354b6glt9mst87m0000gn/T/ipykernel_40275/369624644.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n",
      "/var/folders/lf/9_7wh6ps1354b6glt9mst87m0000gn/T/ipykernel_40275/369624644.py:133: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Define the function to project carbon prices using linear regression\n",
    "# def project_carbon_price(group):\n",
    "#     # Fill missing carbon prices with the median of the group\n",
    "#     group['carbon_price_usd_tco2e_filled'] = group['carbon_price_usd_tco2e'].fillna(group['carbon_price_usd_tco2e'].median())\n",
    "#     # Drop any remaining NaNs (though unlikely after filling unless all values were NaN)\n",
    "#     group_filled = group.dropna(subset=['carbon_price_usd_tco2e_filled'])\n",
    "#     if len(group_filled) >= 2:  # Need at least 2 points for regression\n",
    "#         X = group_filled['year'].values.reshape(-1, 1)\n",
    "#         y = group_filled['carbon_price_usd_tco2e_filled'].values\n",
    "#         model = LinearRegression()\n",
    "#         model.fit(X, y)\n",
    "#         # Predict prices from 2025 to 2050\n",
    "#         years = np.arange(2025, 2051)\n",
    "#         predictions = model.predict(years.reshape(-1, 1))\n",
    "#         return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': predictions})\n",
    "#     else:\n",
    "#         # Return NaN predictions if insufficient data\n",
    "#         years = np.arange(2025, 2051)\n",
    "#         return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': [np.nan] * len(years)})\n",
    "\n",
    "# Apply the projection to get carbon_prices_full\n",
    "carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n",
    "carbon_prices_full = carbon_prices_full.sort_values(by=['sector', 'region', 'scenario', 'year'])\n",
    "\n",
    "# Define the function to calculate carbon costs\n",
    "def calculate_carbon_costs(emissions_paths, carbon_prices_full, df_emissions, start_year=2025, end_year=2050, scenarios=['Low Risk', 'Medium Risk', 'High Risk']):\n",
    "    # Define required columns\n",
    "    required_cols_emissions = ['uid', 'gics_sector', 'country']\n",
    "    required_cols_paths = ['uid', 'year', 'scope1_tonnes', 'scope2_tonnes', 'scenario', 'targeted_emissions']\n",
    "    \n",
    "    # Validate required columns\n",
    "    if not all(col in df_emissions.columns for col in required_cols_emissions):\n",
    "        raise ValueError(\"Missing required columns in df_emissions\")\n",
    "    if not all(col in emissions_paths.columns for col in required_cols_paths):\n",
    "        raise ValueError(\"Missing required columns in emissions_paths\")\n",
    "    \n",
    "    # Scale targeted_emissions to correct for potential thousands-of-tonnes input\n",
    "    emissions_paths['targeted_emissions'] = emissions_paths['targeted_emissions']  # Adjust scaling factor if needed\n",
    "    \n",
    "    # Sector mapping dictionary\n",
    "    sector_mapping = {\n",
    "        'Real Estate': 'Utilities',\n",
    "        'Financials': 'Consumer Discretionary',\n",
    "        'Healthcare': 'Utilities',\n",
    "        'IT': 'Utilities'\n",
    "    }\n",
    "    \n",
    "    # Filter emissions_paths for the 'low' scenario\n",
    "    emissions_paths_low = emissions_paths[emissions_paths['scenario'] == 'low']\n",
    "    \n",
    "    carbon_costs = []\n",
    "    for uid in emissions_paths_low['uid'].unique():\n",
    "        # Get company metadata from df_emissions\n",
    "        company = df_emissions[df_emissions['uid'] == uid]\n",
    "        if company.empty:\n",
    "            continue\n",
    "        sector = company['gics_sector'].iloc[0]\n",
    "        country = company['country'].iloc[0]\n",
    "        \n",
    "        # Map sector if not in carbon_prices_full\n",
    "        mapped_sector = sector_mapping.get(sector, sector) if sector not in carbon_prices_full['sector'].unique() else sector\n",
    "        \n",
    "        # Get carbon prices for the mapped sector and region\n",
    "        prices = carbon_prices_full[\n",
    "            (carbon_prices_full['sector'] == mapped_sector) &\n",
    "            (carbon_prices_full['region'] == country)\n",
    "        ]\n",
    "        if prices.empty:\n",
    "            # Fallback to global prices if region-specific prices are unavailable\n",
    "            prices = carbon_prices_full[\n",
    "                (carbon_prices_full['sector'] == mapped_sector) &\n",
    "                (carbon_prices_full['region'] == 'Global')\n",
    "            ]\n",
    "        \n",
    "        # Sort emissions data by year for this uid\n",
    "        uid_emissions = emissions_paths_low[emissions_paths_low['uid'] == uid].sort_values('year')\n",
    "        prev_targeted_emissions = None\n",
    "        \n",
    "        for year in range(start_year, end_year + 1):\n",
    "            em = uid_emissions[uid_emissions['year'] == year]\n",
    "            if em.empty:\n",
    "                continue\n",
    "            # Calculate total emissions\n",
    "            total_em = em['scope1_tonnes'].iloc[0] + em['scope2_tonnes'].iloc[0]\n",
    "            current_targeted_emissions = em['targeted_emissions'].iloc[0]\n",
    "            \n",
    "            # Calculate abated tonnes as the year-over-year reduction\n",
    "            abated_tonnes = 0\n",
    "            if prev_targeted_emissions is not None:\n",
    "                abated_tonnes = max(0, prev_targeted_emissions - current_targeted_emissions)\n",
    "            prev_targeted_emissions = current_targeted_emissions\n",
    "            \n",
    "            # Iterate over risk scenarios\n",
    "            for risk_scenario in scenarios:\n",
    "                price_row = prices[\n",
    "                    (prices['year'] == year) &\n",
    "                    (prices['scenario'] == risk_scenario)\n",
    "                ]\n",
    "                if price_row.empty:\n",
    "                    continue\n",
    "                price = price_row['carbon_price_usd_tco2e'].iloc[0]\n",
    "                \n",
    "                # Calculate costs\n",
    "                carbon_cost_total_usd = round(total_em * price, 2)\n",
    "                carbon_cost_avoided_usd = round(abated_tonnes * price, 2)\n",
    "                abated_tonnes_cost = round(abated_tonnes * price, 2)  # New column for cost of abated tonnes\n",
    "                \n",
    "                # Append data to the list\n",
    "                carbon_costs.append({\n",
    "                    'uid': uid,\n",
    "                    'sector': mapped_sector,\n",
    "                    'country': country,\n",
    "                    'year': year,\n",
    "                    'risk_scenario': risk_scenario,\n",
    "                    'total_emissions_tonnes': total_em,\n",
    "                    'emissions_abated': abated_tonnes,\n",
    "                    'price_of_carbon': price,\n",
    "                    'carbon_cost_total_usd': carbon_cost_total_usd,\n",
    "                    'carbon_cost_avoided_usd': carbon_cost_avoided_usd,\n",
    "                    'abated_tonnes_cost': abated_tonnes_cost  # Added column\n",
    "                })\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "    return pd.DataFrame(carbon_costs)\n",
    "\n",
    "\n",
    "\n",
    "# Generate projected prices\n",
    "carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n",
    "carbon_prices_full = carbon_prices_full.sort_values(by=['sector', 'region', 'scenario', 'year'])\n",
    "\n",
    "# Calculate carbon costs\n",
    "carbon_costs = calculate_carbon_costs(emissions_paths, carbon_prices_full, df_emissions)\n",
    "# print(carbon_costs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd28c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>country</th>\n",
       "      <th>type_of_target</th>\n",
       "      <th>year</th>\n",
       "      <th>scope1_tonnes</th>\n",
       "      <th>scope2_tonnes</th>\n",
       "      <th>targeted_emissions</th>\n",
       "      <th>scenario</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>interpolation_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2025</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1070000</td>\n",
       "      <td>10700000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2026</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1046588</td>\n",
       "      <td>10465880</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2027</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1023177</td>\n",
       "      <td>10231770</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2028</td>\n",
       "      <td>21510000</td>\n",
       "      <td>999765</td>\n",
       "      <td>9997650</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2029</td>\n",
       "      <td>21510000</td>\n",
       "      <td>976354</td>\n",
       "      <td>9763540</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  gics_sector country type_of_target  year  scope1_tonnes  \\\n",
       "0  C001  Real Estate  Global        Scope 2  2025       21510000   \n",
       "1  C001  Real Estate  Global        Scope 2  2026       21510000   \n",
       "2  C001  Real Estate  Global        Scope 2  2027       21510000   \n",
       "3  C001  Real Estate  Global        Scope 2  2028       21510000   \n",
       "4  C001  Real Estate  Global        Scope 2  2029       21510000   \n",
       "\n",
       "   scope2_tonnes  targeted_emissions scenario  growth_rate  \\\n",
       "0        1070000            10700000      low          0.0   \n",
       "1        1046588            10465880      low          0.0   \n",
       "2        1023177            10231770      low          0.0   \n",
       "3         999765             9997650      low          0.0   \n",
       "4         976354             9763540      low          0.0   \n",
       "\n",
       "  interpolation_method  \n",
       "0               linear  \n",
       "1               linear  \n",
       "2               linear  \n",
       "3               linear  \n",
       "4               linear  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e79fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_prices_full.to_csv(\"carbon_prices_full_projected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def calculate_carbon_costs(emissions_paths, carbon_prices_full):\n",
    "#     # Filter emissions_paths for the 'low' scenario\n",
    "#     emissions_paths_low = emissions_paths[emissions_paths['scenario'] == 'low'] # no growth in production\n",
    "    \n",
    "#     carbon_costs = []\n",
    "#     for uid in emissions_paths_low['uid'].unique():\n",
    "#         # Get company metadata from df_emissions\n",
    "#         company = df_emissions[df_emissions['uid'] == uid]\n",
    "#         if company.empty:\n",
    "#             continue\n",
    "#         sector = company['gics_sector'].iloc[0]\n",
    "#         country = company['country'].iloc[0]\n",
    "        \n",
    "#         # Get carbon prices for this sector and region\n",
    "#         prices = carbon_prices_full[\n",
    "#             (carbon_prices_full['sector'] == sector) &\n",
    "#             (carbon_prices_full['region'] == country)\n",
    "#         ]\n",
    "#         print(\"prices\", prices)\n",
    "#         if prices.empty:\n",
    "#             # Fallback to global prices if region-specific prices are unavailable\n",
    "#             prices = carbon_prices_full[\n",
    "#                 (carbon_prices_full['sector'] == sector) &\n",
    "#                 (carbon_prices_full['region'] == 'Global')\n",
    "#             ]\n",
    "        \n",
    "#         # Sort emissions data by year for this uid\n",
    "#         uid_emissions = emissions_paths_low[emissions_paths_low['uid'] == uid].sort_values('year')\n",
    "#         prev_targeted_emissions = None\n",
    "        \n",
    "#         for year in range(2025, 2051):\n",
    "#             em = uid_emissions[uid_emissions['year'] == year]\n",
    "#             if em.empty:\n",
    "#                 continue\n",
    "#             # Calculate total emissions\n",
    "#             total_em = em['scope1_tonnes'].iloc[0] + em['scope2_tonnes'].iloc[0]\n",
    "#             current_targeted_emissions = em['targeted_emissions'].iloc[0]\n",
    "            \n",
    "#             # Calculate abated tonnes as the year-over-year reduction\n",
    "#             abated_tonnes = 0\n",
    "#             if prev_targeted_emissions is not None:\n",
    "#                 abated_tonnes = max(0, prev_targeted_emissions - current_targeted_emissions)\n",
    "#             prev_targeted_emissions = current_targeted_emissions\n",
    "            \n",
    "#             # Iterate over risk scenarios\n",
    "#             for risk_scenario in ['Low Risk', 'Medium Risk', 'High Risk']:\n",
    "#                 price_row = prices[\n",
    "#                     (prices['year'] == year) &\n",
    "#                     (prices['scenario'] == risk_scenario)\n",
    "#                 ]\n",
    "#                 if price_row.empty:\n",
    "#                     continue\n",
    "#                 price = price_row['carbon_price_usd_tco2e'].iloc[0]\n",
    "                \n",
    "#                 # Calculate costs\n",
    "#                 carbon_cost_total_usd = round(total_em * price, 2)\n",
    "#                 carbon_cost_avoided_usd = round(abated_tonnes * price, 2)\n",
    "                \n",
    "#                 # Append data to the list\n",
    "#                 carbon_costs.append({\n",
    "#                     'uid': uid,\n",
    "#                     'sector': sector,\n",
    "#                     'country': country,\n",
    "#                     'year': year,\n",
    "#                     'risk_scenario': risk_scenario,\n",
    "#                     'total_emissions_tonnes': total_em,\n",
    "#                     'emissions_abated': abated_tonnes,\n",
    "#                     'price_of_carbon': price,\n",
    "#                     'carbon_cost_total_usd': carbon_cost_total_usd,\n",
    "#                     'carbon_cost_avoided_usd': carbon_cost_avoided_usd\n",
    "#                 })\n",
    "    \n",
    "#     # Convert the list to a DataFrame\n",
    "#     return pd.DataFrame(carbon_costs)\n",
    "\n",
    "# # Example usage\n",
    "# carbon_costs = calculate_carbon_costs(emissions_paths, carbon_prices_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb82a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_costs.uid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f658f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_costs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def project_carbon_price(group):\n",
    "#     # Fill missing values within the group\n",
    "#     group['carbon_price_usd_tco2e_filled'] = group['carbon_price_usd_tco2e'].fillna(group['carbon_price_usd_tco2e'].median())\n",
    "#     # Drop any remaining NaNs (though unlikely after filling unless all values were NaN)\n",
    "#     group_filled = group.dropna(subset=['carbon_price_usd_tco2e_filled'])\n",
    "#     if len(group_filled) >= 2:  # Need at least 2 points for regression\n",
    "#         X = group_filled['year'].values.reshape(-1, 1)\n",
    "#         y = group_filled['carbon_price_usd_tco2e_filled'].values\n",
    "#         model = LinearRegression()\n",
    "#         model.fit(X, y)\n",
    "#         years = np.arange(2025, 2051)\n",
    "#         predictions = model.predict(years.reshape(-1, 1))\n",
    "#         return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': predictions})\n",
    "#     else:\n",
    "#         years = np.arange(2025, 2051)\n",
    "#         return pd.DataFrame({'year': years, 'carbon_price_usd_tco2e': [np.nan] * len(years)})\n",
    "\n",
    "# # Apply the projection\n",
    "# carbon_prices_full = df_carbon_prices.groupby(['sector', 'region', 'scenario']).apply(project_carbon_price).reset_index()\n",
    "# carbon_prices_full = carbon_prices_full.sort_values(by=['sector', 'region', 'scenario', 'year'])\n",
    "# # print(carbon_prices_full.head())\n",
    "\n",
    "# # export the projected carbon prices to a CSV file\n",
    "# carbon_prices_full.to_csv(\"projected_carbon_prices.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_carbon_costs(emissions_paths, carbon_prices_full):\n",
    "#     carbon_costs = []\n",
    "#     for uid in emissions_paths['uid'].unique():\n",
    "#         company = df_emissions[df_emissions['uid'] == uid]\n",
    "#         if company.empty:\n",
    "#             continue\n",
    "#         sector, region = company['gics_sector'].iloc[0], company['country'].iloc[0]\n",
    "#         prices = carbon_prices_full[\n",
    "#             (carbon_prices_full['sector'] == sector) &\n",
    "#             (carbon_prices_full['region'] == region)\n",
    "#         ]\n",
    "#         if prices.empty:\n",
    "#             prices = carbon_prices_full[\n",
    "#                 (carbon_prices_full['sector'] == sector) &\n",
    "#                 (carbon_prices_full['region'] == 'Global')\n",
    "#             ]\n",
    "#         for year in range(2025, 2051):\n",
    "#             em = emissions_paths[\n",
    "#                 (emissions_paths['uid'] == uid) &\n",
    "#                 (emissions_paths['year'] == year)\n",
    "#             ]\n",
    "#             if em.empty:\n",
    "#                 continue\n",
    "#             total_em = em['scope1_tonnes'].iloc[0] + em['scope2_tonnes'].iloc[0]\n",
    "#             for scenario in ['Low Risk', 'Medium Risk', 'High Risk']:\n",
    "#                 price_row = prices[\n",
    "#                     (prices['year'] == year) &\n",
    "#                     (prices['scenario'] == scenario)\n",
    "#                 ]\n",
    "#                 if price_row.empty:\n",
    "#                     continue\n",
    "#                 price = price_row['carbon_price_usd_tco2e'].iloc[0]\n",
    "#                 carbon_costs.append({\n",
    "#                     'uid': uid,\n",
    "#                     'year': year,\n",
    "#                     'scenario': scenario,\n",
    "#                     # preserve two decimal places\n",
    "#                     'carbon_cost_usd': round(total_em * price, 2)\n",
    "#                 })\n",
    "#     return pd.DataFrame(carbon_costs)\n",
    "\n",
    "# carbon_costs = calculate_carbon_costs(emissions_paths, carbon_prices_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8241f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the carbon costs to a CSV file\n",
    "carbon_costs.to_csv(\"carbon_costs_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_costs.uid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carbon_prices_energy_global.scenario.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9e300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dfd85ad",
   "metadata": {},
   "source": [
    "Plotting Carbon pricing trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541132f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# make sure DF has required columns\n",
    "required = {\"year\",\"region\",\"sector\",\"scenario\",\"carbon_price_usd_tco2e\"}\n",
    "assert required.issubset(carbon_prices_full.columns), \"missing columns\"\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# MAIN GENERIC FUNCTION\n",
    "# -----------------------------------------------------------------------\n",
    "def plot_region_prices(df, region,\n",
    "                       tool      = \"seaborn\",   # \"seaborn\" or \"plotly\"\n",
    "                       facet     = True,        # only for seaborn: facet per sector?\n",
    "                       log_y     = False,\n",
    "                       ylim      = None):\n",
    "    \"\"\"\n",
    "    df      : master DataFrame\n",
    "    region  : e.g. \"USA\", \"EU\", \"Global\"\n",
    "    tool    : 'seaborn' (static)  or  'plotly' (interactive)\n",
    "    facet   : if seaborn & True  → facet per sector\n",
    "              if False           → one panel, colour = scenario\n",
    "    log_y   : set y-axis to log scale\n",
    "    ylim    : tuple (ymin,ymax) optional manual limits\n",
    "    \"\"\"\n",
    "    sub = df.query(\"region == @region\").copy()\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"No rows for region={region}\")\n",
    "\n",
    "    # optional: mask non-positive values if using log\n",
    "    if log_y:\n",
    "        sub.loc[sub['carbon_price_usd_tco2e'] <= 0, 'carbon_price_usd_tco2e'] = np.nan\n",
    "\n",
    "    # --------------- SEABORN version -----------------------------------\n",
    "    if tool.lower() == \"seaborn\":\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        if facet:\n",
    "            g = sns.relplot(\n",
    "                data=sub, x=\"year\", y=\"carbon_price_usd_tco2e\",\n",
    "                hue=\"scenario\", style=\"scenario\", markers=True,\n",
    "                col=\"sector\", col_wrap=3, linewidth=1, height=3.2\n",
    "            )\n",
    "            g.set_titles(\"{col_name}\")\n",
    "            ax_list = g.axes.flatten()\n",
    "        else:\n",
    "            plt.figure(figsize=(7,4))\n",
    "            ax = sns.lineplot(\n",
    "                data=sub, x=\"year\", y=\"carbon_price_usd_tco2e\",\n",
    "                hue=\"scenario\", style=\"sector\", markers=True, linewidth=1\n",
    "            )\n",
    "            ax_list = [ax]\n",
    "\n",
    "        # log-scale & y-limits\n",
    "        for ax in ax_list:\n",
    "            if log_y: ax.set_yscale('log')\n",
    "            if ylim:  ax.set_ylim(*ylim)\n",
    "\n",
    "        title = (f\"{region} – Carbon-price trajectory \"\n",
    "                 f\"({'facet by sector' if facet else 'all sectors'})\")\n",
    "        if facet:\n",
    "            g.fig.suptitle(title, y=1.03, fontsize=14)\n",
    "            g.set_axis_labels(\"Year\", \"USD / tCO₂e (log)\" if log_y else \"USD / tCO₂e\")\n",
    "        else:\n",
    "            plt.title(title, fontsize=14)\n",
    "            plt.xlabel(\"Year\"); plt.ylabel(\"USD / tCO₂e (log)\" if log_y else \"USD / tCO₂e\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    # --------------- PLOTLY version ------------------------------------\n",
    "    if tool.lower() == \"plotly\":\n",
    "        fig = px.line(\n",
    "            sub, x=\"year\", y=\"carbon_price_usd_tco2e\",\n",
    "            color=\"scenario\", line_dash=\"sector\", markers=True,\n",
    "            hover_data=[\"sector\",\"scenario\",\"carbon_price_usd_tco2e\"],\n",
    "            title=f\"{region} – Carbon-price paths (all sectors)\"\n",
    "        )\n",
    "        fig.update_traces(line_width=1, marker_size=6)\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Year\",\n",
    "            yaxis_title=\"USD / tCO₂e\",\n",
    "            yaxis_type=\"log\" if log_y else \"linear\",\n",
    "            height=600\n",
    "        )\n",
    "        if ylim:\n",
    "            fig.update_yaxes(range=np.log10(ylim).tolist() if log_y else ylim)\n",
    "        fig.show()\n",
    "        return\n",
    "\n",
    "    raise ValueError(\"tool must be 'seaborn' or 'plotly'\")\n",
    "\n",
    "\n",
    "\n",
    "# interactive – Global, single panel, LOG-y\n",
    "plot_region_prices(carbon_prices_full, region=\"EU\", tool=\"plotly\",\n",
    "                   facet=False, log_y=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = carbon_prices_full.copy()\n",
    "plot_df.loc[plot_df['carbon_price_usd_tco2e'] <= 0, 'carbon_price_usd_tco2e'] = np.nan\n",
    "\n",
    "g = sns.relplot(\n",
    "        data      = plot_df,\n",
    "        x         = \"year\",\n",
    "        y         = \"carbon_price_usd_tco2e\",\n",
    "        hue       = \"scenario\",\n",
    "        kind      = \"line\",\n",
    "        marker    = \"o\",\n",
    "        col       = \"region\",\n",
    "        col_wrap  = 3,\n",
    "        height    = 3,\n",
    "        facet_kws = dict(sharey=False)\n",
    ")\n",
    "\n",
    "# put every facet on log-scale\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_yscale('log')\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda v, p: f\"{v:g}\")\n",
    "    )\n",
    "\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\"Trajectory per Sector – coloured by region (log-scaled Y)\", y=1.03)\n",
    "g.set_axis_labels(\"Year\", \"USD / tCO₂e  (log scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngf5_global_carbon_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data = carbon_prices_full,\n",
    "    x=\"year\", y=\"carbon_price_usd_tco2e\",\n",
    "    hue=\"scenario\", kind=\"line\", marker=\"o\",\n",
    "    col=\"sector\", col_wrap=3, height=3, facet_kws={'sharey':False}\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\"Trajectory per Sector – coloured by Scenario\", y=1.02)\n",
    "g.set_axis_labels(\"Year\", \"USD / tCO₂e\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de770d78",
   "metadata": {},
   "source": [
    "Estimate Abatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⊢ Filtered to 1,196 rows  (45 companies)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Abatement-cost engine  v1.1-lite\n",
    "(c) 2025  –  delta-based capacity build / reuse\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 0.  Pathway filter\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def filter_paths(df: pd.DataFrame,\n",
    "                 scenario: str = \"low\",\n",
    "                 interp:   str = \"linear\",\n",
    "                 verbose:  bool = True) -> pd.DataFrame:\n",
    "    out = df.query(\"scenario == @scenario and interpolation_method == @interp\").copy()\n",
    "    if out.empty:\n",
    "        raise ValueError(\"No rows for the chosen scenario / interpolation.\")\n",
    "    if verbose:\n",
    "        print(f\"⊢ Filtered to {len(out):,} rows  ({out['uid'].nunique()} companies)\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Technology filter\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def filter_tech_by_location_sector(df_abatement: pd.DataFrame,\n",
    "                                   location: str,\n",
    "                                   sector:   str) -> pd.DataFrame:\n",
    "    tech = df_abatement[(df_abatement[\"sector\"] == sector) &\n",
    "                        (df_abatement[\"region\"] == location)]\n",
    "    if tech.empty:\n",
    "        tech = df_abatement[(df_abatement[\"sector\"] == sector) &\n",
    "                            (df_abatement[\"region\"] == \"Global\")]\n",
    "    if tech.empty:\n",
    "        tech = df_abatement[df_abatement[\"region\"] == \"Global\"]\n",
    "    if tech.empty:\n",
    "        raise ValueError(f\"No abatement tech for {sector=} {location=}.\")\n",
    "    return tech.copy()\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2.  Δ-tonnes needed this year\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def tonnes_to_abate(df_paths: pd.DataFrame,\n",
    "                    uid: str,\n",
    "                    year: int,\n",
    "                    tgt: str,\n",
    "                    prev_allowed: float | None) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    tonnes_needed  =  allowed_{t-1}  –  allowed_{t}      ( ≥ 0 )\n",
    "    allowed_now    =  Scope-1 / Scope-2 / (1+2) for year t\n",
    "    \"\"\"\n",
    "    row = df_paths.query(\"uid == @uid and year == @year\").iloc[0]\n",
    "\n",
    "    # pick the right column(s)\n",
    "    if tgt == \"Scope 1\":\n",
    "        allowed_now = row[\"scope1_tonnes\"]\n",
    "    elif tgt == \"Scope 2\":\n",
    "        allowed_now = row[\"scope2_tonnes\"]\n",
    "    else:                                   # Combined\n",
    "        allowed_now = row[\"scope1_tonnes\"] + row[\"scope2_tonnes\"]\n",
    "\n",
    "    # first model year: no reduction yet → Δ = 0\n",
    "    if prev_allowed is None:\n",
    "        tonnes_needed = 0.0\n",
    "    else:\n",
    "        tonnes_needed = max(prev_allowed - allowed_now, 0.0)\n",
    "\n",
    "    return tonnes_needed, allowed_now\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Dispatcher  – reuse spare → build cheapest new plants\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Dispatcher  – reuse installed capacity, build when needed\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def dispatch_with_capacity(tech_df: pd.DataFrame,\n",
    "                           tonnes_needed: float,\n",
    "                           capacity_bank: Dict[str, float]\n",
    "                           ) -> tuple[list[dict], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tech_df        : menu of abatement technologies allowed for this company\n",
    "    tonnes_needed  : Δ-tonnes to abate in the current year\n",
    "    capacity_bank  : {technology: total_installed_capacity}  (tCO₂e / yr)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    packages       : list of build / reuse actions taken this year\n",
    "    capacity_bank  : updated bank for next year\n",
    "    \"\"\"\n",
    "    packages: list[dict] = []\n",
    "\n",
    "    # ----------------------------------------------------------- #\n",
    "    # 1️⃣  Re-use capacity already installed in previous years\n",
    "    # ----------------------------------------------------------- #\n",
    "    for tech, cap in capacity_bank.items():\n",
    "        if tonnes_needed <= 0:\n",
    "            break\n",
    "        take = min(cap, tonnes_needed)          # can’t exceed rated capacity\n",
    "        if take > 0:\n",
    "            r     = tech_df.loc[tech_df[\"technology\"] == tech].iloc[0]\n",
    "            opex  = r[\"abatement_cost_usd_tco2e_year\"] * take\n",
    "            packages.append({\n",
    "                \"technology\": tech,\n",
    "                \"new_build\":  False,\n",
    "                \"tonnes\":     take,\n",
    "                \"plant_capacity\": cap,          # full rated capacity\n",
    "                \"capex_usd\":  0.0,\n",
    "                \"opex_usd_year\": opex,\n",
    "                \"cost_per_tonne_abated\": opex / take,\n",
    "                \"abatement_tech_sector\": r[\"sector\"],\n",
    "            })\n",
    "            tonnes_needed -= take               # capacity is re-usable next year\n",
    "\n",
    "    # ----------------------------------------------------------- #\n",
    "    # 2️⃣  Build new plants (cheapest first) if demand still unmet\n",
    "    # ----------------------------------------------------------- #\n",
    "    if tonnes_needed > 0:\n",
    "        tech_df = tech_df.assign(\n",
    "            levelised=(tech_df[\"initial_investment_usd_million\"] * 1e6\n",
    "                       / tech_df[\"abatement_capacity_tco2e_year\"]\n",
    "                       + tech_df[\"abatement_cost_usd_tco2e_year\"])\n",
    "        ).sort_values(\"levelised\")\n",
    "\n",
    "        for _, r in tech_df.iterrows():\n",
    "            if tonnes_needed <= 0:\n",
    "                break\n",
    "\n",
    "            cap   = r[\"abatement_capacity_tco2e_year\"]\n",
    "            take  = min(cap, tonnes_needed)\n",
    "            capex = r[\"initial_investment_usd_million\"] * 1e6\n",
    "            opex  = r[\"abatement_cost_usd_tco2e_year\"] * take\n",
    "\n",
    "            packages.append({\n",
    "                \"technology\": r[\"technology\"],\n",
    "                \"new_build\":  True,\n",
    "                \"tonnes\":     take,\n",
    "                \"plant_capacity\": cap,\n",
    "                \"capex_usd\":  capex,\n",
    "                \"opex_usd_year\": opex,\n",
    "                \"cost_per_tonne_abated\": (capex / cap) + r[\"abatement_cost_usd_tco2e_year\"],\n",
    "                \"abatement_tech_sector\": r[\"sector\"],\n",
    "            })\n",
    "\n",
    "            # 🔑  add the new plant’s capacity to any that already exists\n",
    "            capacity_bank[r[\"technology\"]] = capacity_bank.get(r[\"technology\"], 0) + cap\n",
    "            tonnes_needed -= take\n",
    "\n",
    "    return packages, capacity_bank\n",
    "\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4.  Per-company engine\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "TARGET_MAP = {\n",
    "    \"Scope 1\":            \"Scope 1\",\n",
    "    \"Scope 2\":            \"Scope 2\",\n",
    "    \"Direct\":             \"Combined\",\n",
    "    \"Scope 2 and other\":  \"Combined\",\n",
    "}\n",
    "\n",
    "def compute_company_abatement_costs(uid: str,\n",
    "                                    df_paths: pd.DataFrame,\n",
    "                                    df_abatement: pd.DataFrame\n",
    "                                    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    comp = df_paths[df_paths[\"uid\"] == uid]\n",
    "    if comp.empty:\n",
    "        raise ValueError(f\"{uid=} missing in pathway data.\")\n",
    "\n",
    "    raw_tgt = comp[\"type_of_target\"].iat[0]\n",
    "    if raw_tgt == \"Scope 3\":\n",
    "        warnings.warn(f\"Skipping {uid}: Scope 3 target (not modelled).\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    tgt = TARGET_MAP.get(raw_tgt)\n",
    "    if tgt is None:\n",
    "        warnings.warn(f\"Skipping {uid}: unknown target '{raw_tgt}'.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    sector   = comp[\"gics_sector\"].iat[0]\n",
    "    location = comp[\"country\"].iat[0]\n",
    "    tech_df  = filter_tech_by_location_sector(df_abatement, location, sector)\n",
    "\n",
    "    capacity_bank: Dict[str, float] = {}\n",
    "    annual_rows:  List[dict] = []\n",
    "    detail_rows:  List[dict] = []\n",
    "    cum_capex = cum_opex = 0.0\n",
    "    prev_allowed: float | None = None\n",
    "\n",
    "    for year in sorted(comp[\"year\"].unique()):\n",
    "        tonnes_needed, allowed_now = tonnes_to_abate(df_paths, uid, year, tgt, prev_allowed)\n",
    "        packages, capacity_bank = dispatch_with_capacity(tech_df, tonnes_needed, capacity_bank)\n",
    "\n",
    "        capex = sum(p[\"capex_usd\"]     for p in packages)\n",
    "        opex  = sum(p[\"opex_usd_year\"] for p in packages)\n",
    "        cum_capex += capex\n",
    "        cum_opex  += opex\n",
    "\n",
    "        annual_rows.append({\n",
    "            \"uid\": uid, \"year\": year, \"region\": location, \"gics_sector\": sector,\n",
    "            \"abatement_tonnes\": tonnes_needed,\n",
    "            \"capex_usd\": capex, \"opex_usd_year\": opex,\n",
    "            \"cum_capex_usd\": cum_capex, \"cum_opex_usd\": cum_opex,\n",
    "            \"technology_used\": \"; \".join(p[\"technology\"] for p in packages),\n",
    "            \"plant_capacity_built_this_year\": sum(\n",
    "                p[\"plant_capacity\"] for p in packages if p[\"new_build\"]),\n",
    "        })\n",
    "\n",
    "        for p in packages:\n",
    "            detail_rows.append({**p, \"uid\": uid, \"year\": year,\n",
    "                                \"region\": location, \"gics_sector\": sector})\n",
    "\n",
    "        prev_allowed = allowed_now\n",
    "\n",
    "    return pd.DataFrame(annual_rows), pd.DataFrame(detail_rows)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5.  Portfolio runner\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def run_all_companies(df_paths: pd.DataFrame,\n",
    "                      df_abatement: pd.DataFrame\n",
    "                      ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    annual_frames, detail_frames = [], []\n",
    "    for uid in df_paths[\"uid\"].unique():\n",
    "        annual, detail = compute_company_abatement_costs(uid, df_paths, df_abatement)\n",
    "        if not annual.empty:\n",
    "            annual_frames.append(annual)\n",
    "            detail_frames.append(detail)\n",
    "\n",
    "    if not annual_frames:\n",
    "        raise ValueError(\"No company produced output – check target labels.\")\n",
    "\n",
    "    annual_df = pd.concat(annual_frames, ignore_index=True)\n",
    "    detail_df = pd.concat(detail_frames, ignore_index=True)\n",
    "    summary_df = (annual_df.groupby(\"uid\")\n",
    "                  .agg(total_capex_usd     = (\"capex_usd\", \"sum\"),\n",
    "                       total_opex_usd      = (\"opex_usd_year\", \"sum\"),\n",
    "                       total_abated_tonnes = (\"abatement_tonnes\", \"sum\"),\n",
    "                       region              = (\"region\", \"first\"),\n",
    "                       gics_sector         = (\"gics_sector\", \"first\"))\n",
    "                  .reset_index())\n",
    "    return annual_df, summary_df, detail_df\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6.  Example (comment out SystemExit when real data are loaded)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # raise SystemExit(\n",
    "    #     \"Load `emissions_paths` & `df_abatement`, then:\\n\")\n",
    "        paths = filter_paths(emissions_paths, 'low', 'linear')\n",
    "        annual_df, summary_df, detail_df = run_all_companies(paths, df_abatement)\n",
    "        annual_df.to_csv('annual_abatement_costs.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5a304d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>country</th>\n",
       "      <th>type_of_target</th>\n",
       "      <th>year</th>\n",
       "      <th>scope1_tonnes</th>\n",
       "      <th>scope2_tonnes</th>\n",
       "      <th>targeted_emissions</th>\n",
       "      <th>scenario</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>interpolation_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2025</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1070000</td>\n",
       "      <td>10700000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2026</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1046588</td>\n",
       "      <td>10465880</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2027</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1023177</td>\n",
       "      <td>10231770</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2028</td>\n",
       "      <td>21510000</td>\n",
       "      <td>999765</td>\n",
       "      <td>9997650</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2029</td>\n",
       "      <td>21510000</td>\n",
       "      <td>976354</td>\n",
       "      <td>9763540</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  gics_sector country type_of_target  year  scope1_tonnes  \\\n",
       "0  C001  Real Estate  Global        Scope 2  2025       21510000   \n",
       "1  C001  Real Estate  Global        Scope 2  2026       21510000   \n",
       "2  C001  Real Estate  Global        Scope 2  2027       21510000   \n",
       "3  C001  Real Estate  Global        Scope 2  2028       21510000   \n",
       "4  C001  Real Estate  Global        Scope 2  2029       21510000   \n",
       "\n",
       "   scope2_tonnes  targeted_emissions scenario  growth_rate  \\\n",
       "0        1070000            10700000      low          0.0   \n",
       "1        1046588            10465880      low          0.0   \n",
       "2        1023177            10231770      low          0.0   \n",
       "3         999765             9997650      low          0.0   \n",
       "4         976354             9763540      low          0.0   \n",
       "\n",
       "  interpolation_method  \n",
       "0               linear  \n",
       "1               linear  \n",
       "2               linear  \n",
       "3               linear  \n",
       "4               linear  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a14d435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>country</th>\n",
       "      <th>type_of_target</th>\n",
       "      <th>year</th>\n",
       "      <th>scope1_tonnes</th>\n",
       "      <th>scope2_tonnes</th>\n",
       "      <th>targeted_emissions</th>\n",
       "      <th>scenario</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>interpolation_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2025</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1070000</td>\n",
       "      <td>10700000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2026</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1046588</td>\n",
       "      <td>10465880</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2027</td>\n",
       "      <td>21510000</td>\n",
       "      <td>1023177</td>\n",
       "      <td>10231770</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2028</td>\n",
       "      <td>21510000</td>\n",
       "      <td>999765</td>\n",
       "      <td>9997650</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Global</td>\n",
       "      <td>Scope 2</td>\n",
       "      <td>2029</td>\n",
       "      <td>21510000</td>\n",
       "      <td>976354</td>\n",
       "      <td>9763540</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  gics_sector country type_of_target  year  scope1_tonnes  \\\n",
       "0  C001  Real Estate  Global        Scope 2  2025       21510000   \n",
       "1  C001  Real Estate  Global        Scope 2  2026       21510000   \n",
       "2  C001  Real Estate  Global        Scope 2  2027       21510000   \n",
       "3  C001  Real Estate  Global        Scope 2  2028       21510000   \n",
       "4  C001  Real Estate  Global        Scope 2  2029       21510000   \n",
       "\n",
       "   scope2_tonnes  targeted_emissions scenario  growth_rate  \\\n",
       "0        1070000            10700000      low          0.0   \n",
       "1        1046588            10465880      low          0.0   \n",
       "2        1023177            10231770      low          0.0   \n",
       "3         999765             9997650      low          0.0   \n",
       "4         976354             9763540      low          0.0   \n",
       "\n",
       "  interpolation_method  \n",
       "0               linear  \n",
       "1               linear  \n",
       "2               linear  \n",
       "3               linear  \n",
       "4               linear  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_paths.query(\"uid == 'C001'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2efab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scope 2', 'Scope 1', 'Direct', 'Scope 2 and other'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_paths.type_of_target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57485461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>region</th>\n",
       "      <th>technology</th>\n",
       "      <th>initial_investment_usd_million</th>\n",
       "      <th>abatement_capacity_tco2e_year</th>\n",
       "      <th>abatement_cost_usd_tco2e_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>Utility-scale Solar</td>\n",
       "      <td>350.52</td>\n",
       "      <td>60952</td>\n",
       "      <td>50.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wind Power</td>\n",
       "      <td>218.94</td>\n",
       "      <td>192720</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Energy</td>\n",
       "      <td>EU</td>\n",
       "      <td>Utility-scale Solar</td>\n",
       "      <td>558.64</td>\n",
       "      <td>54776</td>\n",
       "      <td>44.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy</td>\n",
       "      <td>EU</td>\n",
       "      <td>Carbon Capture and Storage</td>\n",
       "      <td>340.98</td>\n",
       "      <td>50000</td>\n",
       "      <td>105.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Energy</td>\n",
       "      <td>China</td>\n",
       "      <td>Utility-scale Solar</td>\n",
       "      <td>380.28</td>\n",
       "      <td>217543</td>\n",
       "      <td>43.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sector region                  technology  initial_investment_usd_million  \\\n",
       "0  Energy    USA         Utility-scale Solar                          350.52   \n",
       "1  Energy    USA                  Wind Power                          218.94   \n",
       "2  Energy     EU         Utility-scale Solar                          558.64   \n",
       "3  Energy     EU  Carbon Capture and Storage                          340.98   \n",
       "4  Energy  China         Utility-scale Solar                          380.28   \n",
       "\n",
       "   abatement_capacity_tco2e_year  abatement_cost_usd_tco2e_year  \n",
       "0                          60952                          50.97  \n",
       "1                         192720                          31.15  \n",
       "2                          54776                          44.22  \n",
       "3                          50000                         105.16  \n",
       "4                         217543                          43.47  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abatement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd09227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>abatement_tonnes</th>\n",
       "      <th>capex_usd</th>\n",
       "      <th>opex_usd_year</th>\n",
       "      <th>cum_capex_usd</th>\n",
       "      <th>cum_opex_usd</th>\n",
       "      <th>technology_used</th>\n",
       "      <th>plant_capacity_built_this_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>2025</td>\n",
       "      <td>Global</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>2026</td>\n",
       "      <td>Global</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>23412.0</td>\n",
       "      <td>77400000.0</td>\n",
       "      <td>1101066.36</td>\n",
       "      <td>77400000.0</td>\n",
       "      <td>1101066.36</td>\n",
       "      <td>Energy Efficiency Upgrades</td>\n",
       "      <td>39466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001</td>\n",
       "      <td>2027</td>\n",
       "      <td>Global</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>23411.0</td>\n",
       "      <td>77400000.0</td>\n",
       "      <td>1101019.33</td>\n",
       "      <td>154800000.0</td>\n",
       "      <td>2202085.69</td>\n",
       "      <td>Energy Efficiency Upgrades; Energy Efficiency ...</td>\n",
       "      <td>39466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C001</td>\n",
       "      <td>2028</td>\n",
       "      <td>Global</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>23412.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1101066.36</td>\n",
       "      <td>154800000.0</td>\n",
       "      <td>3303152.05</td>\n",
       "      <td>Energy Efficiency Upgrades</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C001</td>\n",
       "      <td>2029</td>\n",
       "      <td>Global</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>23411.0</td>\n",
       "      <td>77400000.0</td>\n",
       "      <td>1101019.33</td>\n",
       "      <td>232200000.0</td>\n",
       "      <td>4404171.38</td>\n",
       "      <td>Energy Efficiency Upgrades; Energy Efficiency ...</td>\n",
       "      <td>39466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  year  region  gics_sector  abatement_tonnes   capex_usd  \\\n",
       "0  C001  2025  Global  Real Estate               0.0         0.0   \n",
       "1  C001  2026  Global  Real Estate           23412.0  77400000.0   \n",
       "2  C001  2027  Global  Real Estate           23411.0  77400000.0   \n",
       "3  C001  2028  Global  Real Estate           23412.0         0.0   \n",
       "4  C001  2029  Global  Real Estate           23411.0  77400000.0   \n",
       "\n",
       "   opex_usd_year  cum_capex_usd  cum_opex_usd  \\\n",
       "0           0.00            0.0          0.00   \n",
       "1     1101066.36     77400000.0    1101066.36   \n",
       "2     1101019.33    154800000.0    2202085.69   \n",
       "3     1101066.36    154800000.0    3303152.05   \n",
       "4     1101019.33    232200000.0    4404171.38   \n",
       "\n",
       "                                     technology_used  \\\n",
       "0                                                      \n",
       "1                         Energy Efficiency Upgrades   \n",
       "2  Energy Efficiency Upgrades; Energy Efficiency ...   \n",
       "3                         Energy Efficiency Upgrades   \n",
       "4  Energy Efficiency Upgrades; Energy Efficiency ...   \n",
       "\n",
       "   plant_capacity_built_this_year  \n",
       "0                               0  \n",
       "1                           39466  \n",
       "2                           39466  \n",
       "3                               0  \n",
       "4                           39466  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_df.head()# emissions_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abatement.query(\"region == 'Global'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_paths.query(\"uid=='C001'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_paths(df, scenario='med', interp='linear'):\n",
    "#     return df.query(\"scenario == @scenario and interpolation_method == @interp\").copy()\n",
    "\n",
    "# all_yearly, company_totals = run_all_companies(\n",
    "#     filter_paths(emissions_paths, 'med', 'linear'),\n",
    "#     df_abatement\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7161bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d751ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_tradeoff_table(annual_df, emissions_paths, carbon_prices_full):\n",
    "    # ── 1. Merge emissions + abatement ────────────────────────────────\n",
    "    emis = (emissions_paths\n",
    "            .assign(e_total=lambda d: d['scope1_tonnes'] + d['scope2_tonnes'])\n",
    "            .loc[:, ['uid', 'year', 'gics_sector', 'country', 'e_total']])\n",
    "\n",
    "    abat = (annual_df\n",
    "            .loc[:, ['uid', 'year',\n",
    "                     'abatement_tonnes', 'capex_usd', 'opex_usd_year']]\n",
    "            .sort_values(['uid', 'year'])\n",
    "            .assign(capex_cum=lambda d: d.groupby('uid')['capex_usd'].cumsum(),\n",
    "                    opex_cum =lambda d: d.groupby('uid')['opex_usd_year'].cumsum()))\n",
    "\n",
    "    base = emis.merge(abat, on=['uid', 'year'], how='left').fillna(0)\n",
    "\n",
    "    # ── 2. Cross-join every scenario (Low / Medium / High) ────────────\n",
    "    scenarios = carbon_prices_full['scenario'].unique()\n",
    "    base = (base.assign(key=1)\n",
    "                 .merge(pd.DataFrame({'scenario': scenarios, 'key': 1}),\n",
    "                        on='key').drop('key', axis=1))\n",
    "\n",
    "    # ── 3. Attach carbon prices with Global fallback ──────────────────\n",
    "    price_cols = ['sector', 'region', 'scenario',\n",
    "                  'year', 'carbon_price_usd_tco2e']\n",
    "    prices = carbon_prices_full[price_cols]\n",
    "\n",
    "    df = base.merge(\n",
    "        prices,\n",
    "        left_on =['gics_sector','country','scenario','year'],\n",
    "        right_on=['sector'     ,'region' ,'scenario','year'],\n",
    "        how='left')\n",
    "\n",
    "    miss = df['carbon_price_usd_tco2e'].isna()\n",
    "    if miss.any():\n",
    "        global_prices = prices[prices['region'] == 'Global']\n",
    "        df.loc[miss, 'carbon_price_usd_tco2e'] = (\n",
    "            df[miss]\n",
    "            .merge(global_prices,\n",
    "                   on=['sector','scenario','year'],\n",
    "                   how='left')['carbon_price_usd_tco2e_y']\n",
    "        )\n",
    "\n",
    "    # ── 4. Compute cost metrics ───────────────────────────────────────\n",
    "    df['carbon_cost_without_usd'] = df['e_total'] * df['carbon_price_usd_tco2e']\n",
    "    df['carbon_cost_with_usd']    = (\n",
    "        (df['e_total'] - df['abatement_tonnes']) *\n",
    "        df['carbon_price_usd_tco2e']\n",
    "    )\n",
    "    df['total_cost_with_abatement_usd'] = (\n",
    "        df['capex_cum'] + df['opex_cum'] + df['carbon_cost_with_usd']\n",
    "    )\n",
    "    df['net_savings_usd'] = (\n",
    "        df['carbon_cost_without_usd'] - df['total_cost_with_abatement_usd']\n",
    "    )\n",
    "\n",
    "    return df[['uid','scenario','year',\n",
    "               'carbon_cost_without_usd',\n",
    "               'total_cost_with_abatement_usd',\n",
    "               'net_savings_usd']]\n",
    "\n",
    "tradeoffs = build_tradeoff_table(annual_df, emissions_paths, carbon_prices_full)\n",
    "\n",
    "# ── Export the tradeoff table ───────────────────────────────────────\n",
    "tradeoffs.to_csv(\"tradeoff_table.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfe66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tradeoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a7167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdd348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
